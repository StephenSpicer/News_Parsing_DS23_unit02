{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our preamble cell :\n",
    "# remember to check for anything missing \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real data shape:  (21417, 5)\n",
      "Fake data shape:  (23481, 5)\n"
     ]
    }
   ],
   "source": [
    "# OK, importing and minor cleaning first. \n",
    "\n",
    "dfreal = pd.read_csv('True.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "dfreal['Fake'] = 0\n",
    "print('Real data shape: ', dfreal.shape)\n",
    "\n",
    "dffake = pd.read_csv('Fake.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "\n",
    "dffake['Fake'] = 1\n",
    "print('Fake data shape: ', dffake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20    182\n",
       "2017-12-06    166\n",
       "2017-11-30    162\n",
       "2017-11-09    158\n",
       "2017-10-13    155\n",
       "             ... \n",
       "2016-09-11      1\n",
       "2016-05-14      1\n",
       "2016-05-30      1\n",
       "2016-08-06      1\n",
       "2016-09-03      1\n",
       "Name: date, Length: 716, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# this is proof that only the fake csv has garbage dates in it, which is why none of the parse dates worked. \n",
    "dfreal['date'].value_counts()\n",
    "#.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "May 10, 2017                                                                                                                                             46\n",
       "May 5, 2016                                                                                                                                              44\n",
       "May 26, 2016                                                                                                                                             44\n",
       "May 6, 2016                                                                                                                                              44\n",
       "May 11, 2016                                                                                                                                             43\n",
       "                                                                                                                                                         ..\n",
       "November 20, 2017                                                                                                                                         1\n",
       "November 19, 2017                                                                                                                                         1\n",
       "https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/     1\n",
       "October 9, 2017                                                                                                                                           1\n",
       "Jul 19, 2015                                                                                                                                              1\n",
       "Name: date, Length: 1681, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "dffake['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(23481, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "\n",
    "# dffake = \n",
    "comma_list = pd.DataFrame(dffake['date'].str.find(','))\n",
    "\n",
    "comma_list.value_counts()\n",
    "comma_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~df['your column'].isin(['list of strings'])]\n",
    "# http = ['http',\".com\"]\n",
    "# dffake2 = dffake[~dffake.date.isin(http)]\n",
    "\n",
    "searchfor = ['http', '-', 'MSNBC']\n",
    "dffake2 = dffake[~dffake['date'].str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "May 10, 2017         46\n",
       "May 26, 2016         44\n",
       "May 6, 2016          44\n",
       "May 5, 2016          44\n",
       "May 11, 2016         43\n",
       "                     ..\n",
       "October 9, 2017       1\n",
       "December 19, 2017     1\n",
       "November 19, 2017     1\n",
       "October 22, 2017      1\n",
       "December 9, 2017      1\n",
       "Name: date, Length: 1669, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "dffake2['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(23436, 5)\n(21417, 5)\n"
     ]
    }
   ],
   "source": [
    "print(dffake2.shape)\n",
    "print(dfreal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dffake2['date'] = pd.to_datetime(dffake2['date'], format='%m%d%y')\n",
    "# dffake2['date'] = dffake2['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real trimmed shape:  (21400, 5)\nFake trimmed shape:  (21400, 5)\n\nCombined and trimmed (equal parts Real and Fake) shape:  (42800, 5)\n\n"
     ]
    }
   ],
   "source": [
    "# now I'll trim those up so they are the same length - \n",
    "# 50% real 50% fake seems reasonable right?\n",
    "\n",
    "dfreal_trimmed = dfreal[-21_400 :]\n",
    "print('Real trimmed shape: ', dfreal_trimmed.shape)\n",
    "\n",
    "dffake_trimmed = dffake2[-21_400 :]\n",
    "print('Fake trimmed shape: ', dffake_trimmed.shape)\n",
    "\n",
    "# and now combine them into one dataframe:\n",
    "df_joined = dfreal_trimmed.append(dffake_trimmed, ignore_index=True)\n",
    "\n",
    "df_joined['date'] = pd.to_datetime(df_joined['date'])\n",
    "\n",
    "print()\n",
    "print('Combined and trimmed (equal parts Real and Fake) shape: ', df_joined.shape)\n",
    "print()\n",
    "#print(df_joined.head(1))\n",
    "#df_joined.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20    194\n",
       "2017-12-06    180\n",
       "2017-11-09    178\n",
       "2017-11-30    175\n",
       "2017-10-13    171\n",
       "             ... \n",
       "2015-06-21      1\n",
       "2015-06-07      1\n",
       "2015-07-19      1\n",
       "2015-07-18      1\n",
       "2015-04-02      1\n",
       "Name: date, Length: 1004, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "df_joined['date'].value_counts()\n",
    "\n",
    "# Holy Smokes I think all the date times are clean. \n",
    "# Let's never spend 2 days on that again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All URL's and Wrong-Dates seem to be corrected. Finally.  \n",
    "# X and y are still not the same length - need to fix that... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:  (42800, 4)\ny shape:  (42800,)\n"
     ]
    }
   ],
   "source": [
    "# X and y split\n",
    "\n",
    "target = df_joined['Fake']\n",
    "\n",
    "X = df_joined.drop(['Fake'], axis=1)\n",
    "\n",
    "y = target\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline : 0.5\n"
     ]
    }
   ],
   "source": [
    "# this is silly but it's good form, so here's a baseline. \n",
    "print('Baseline :', df_joined['Fake'].value_counts().max()/len(df_joined['Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split:\n",
    "\n",
    "# leaving this code here in case I set up my target wrong. \n",
    "# X = df.drop(['target'],axis=1).values   # independant features\n",
    "# y = df['target'].values\t\t\t\t\t# dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# doing 25/75 split and 42. \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24075, 4)\n(24075,)\n(8025, 4)\n(8025,)\n(10700, 4)\n(10700,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wonderful. All variables should be set up the right way... but I will still check in with someone about whether I did this right. "
   ]
  },
  {
   "source": [
    "## *I don't think we'll use this but here's a Count Vectorizer just in case:*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          according      american        called      campaign       clinton  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.315047      0.360117      0.295794      0.483505      0.618014   \n",
       "std        0.787854      1.065031      0.658973      1.347394      2.304309   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       20.000000     48.000000     10.000000     31.000000     67.000000   \n",
       "\n",
       "            country         court    democratic           did        donald  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.389159      0.329299      0.303575      0.369673      0.590771   \n",
       "std        0.904674      1.353023      0.888128      0.797977      1.020930   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max       26.000000     43.000000     18.000000     20.000000     32.000000   \n",
       "\n",
       "       ...       support          time          told         trump  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.297734      0.460935      0.529416      2.523014   \n",
       "std    ...      0.768017      0.910293      0.939773      4.386813   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      1.000000      1.000000      3.000000   \n",
       "max    ...     24.000000     28.000000     13.000000     73.000000   \n",
       "\n",
       "             united    washington          week         white          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.536028      0.422009      0.299813      0.483178      0.557126   \n",
       "std        1.283105      0.954925      0.675320      1.305252      1.120097   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max       42.000000     35.000000     10.000000     36.000000     27.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.386589  \n",
       "std        0.890714  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max       61.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>according</th>\n      <th>american</th>\n      <th>called</th>\n      <th>campaign</th>\n      <th>clinton</th>\n      <th>country</th>\n      <th>court</th>\n      <th>democratic</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>...</th>\n      <th>support</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>week</th>\n      <th>white</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.315047</td>\n      <td>0.360117</td>\n      <td>0.295794</td>\n      <td>0.483505</td>\n      <td>0.618014</td>\n      <td>0.389159</td>\n      <td>0.329299</td>\n      <td>0.303575</td>\n      <td>0.369673</td>\n      <td>0.590771</td>\n      <td>...</td>\n      <td>0.297734</td>\n      <td>0.460935</td>\n      <td>0.529416</td>\n      <td>2.523014</td>\n      <td>0.536028</td>\n      <td>0.422009</td>\n      <td>0.299813</td>\n      <td>0.483178</td>\n      <td>0.557126</td>\n      <td>0.386589</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.787854</td>\n      <td>1.065031</td>\n      <td>0.658973</td>\n      <td>1.347394</td>\n      <td>2.304309</td>\n      <td>0.904674</td>\n      <td>1.353023</td>\n      <td>0.888128</td>\n      <td>0.797977</td>\n      <td>1.020930</td>\n      <td>...</td>\n      <td>0.768017</td>\n      <td>0.910293</td>\n      <td>0.939773</td>\n      <td>4.386813</td>\n      <td>1.283105</td>\n      <td>0.954925</td>\n      <td>0.675320</td>\n      <td>1.305252</td>\n      <td>1.120097</td>\n      <td>0.890714</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20.000000</td>\n      <td>48.000000</td>\n      <td>10.000000</td>\n      <td>31.000000</td>\n      <td>67.000000</td>\n      <td>26.000000</td>\n      <td>43.000000</td>\n      <td>18.000000</td>\n      <td>20.000000</td>\n      <td>32.000000</td>\n      <td>...</td>\n      <td>24.000000</td>\n      <td>28.000000</td>\n      <td>13.000000</td>\n      <td>73.000000</td>\n      <td>42.000000</td>\n      <td>35.000000</td>\n      <td>10.000000</td>\n      <td>36.000000</td>\n      <td>27.000000</td>\n      <td>61.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "# instantiate the count vectorizer:\n",
    "cv = CountVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, max_df = 0.95 , min_df = 0.01 )\n",
    "\n",
    "# here's a function to return a dataframe:\n",
    "\n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "# now here's the actual \"thing\":\n",
    "\n",
    "df_joined_CountVector = create_term_matrix(df_joined['text'], cv)\n",
    "\n",
    "df_joined_CountVector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-IDF Vectorizer are the same results are doing a Count Vectorizer followed by a Tf-IDF Transform. \n",
    "# GradientBoostingClassifier. Good thing we learned some params today. \n",
    "# \n",
    "# I still have questions regarding how to merge the results from this with my orginal df_joined(41,800 x 5) - so pin in that for now. \n",
    "\n",
    "# \n",
    "# create a dictionary for myself (ex: year and years same word) - (sisichen)\n",
    "# find an NLP function that can cluster similiar words together - lookup common NLP functions - (sisichen)\n",
    "\n",
    "# merging original frame and target vector with results so that I can train test split and fit model...\n",
    "# Ngrams. They exist in the parameters for the vectorizer / model below... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                did        donald    government         house          just  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.057967      0.074543      0.095066      0.085921      0.081424   \n",
       "std        0.124761      0.119868      0.190222      0.177617      0.157294   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.052837      0.122746      0.113759      0.091760      0.114470   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               like           new          news        people     president  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.077734      0.093882      0.076336      0.120271      0.139008   \n",
       "std        0.158628      0.168228      0.168455      0.192616      0.183971   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.065831   \n",
       "75%        0.098803      0.140322      0.056671      0.186142      0.230169   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...          said         state        states          time  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.284245      0.105763      0.081423      0.070897   \n",
       "std    ...      0.254718      0.197059      0.150857      0.139093   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.245803      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.470852      0.144302      0.122473      0.103245   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               told         trump        united    washington          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.080758      0.240842      0.075819      0.068428      0.084785   \n",
       "std        0.142268      0.313414      0.152301      0.136795      0.161222   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.130172      0.492389      0.087407      0.088721      0.121459   \n",
       "max        1.000000      1.000000      0.980876      1.000000      1.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.061514  \n",
       "std        0.132984  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.039246  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.057967</td>\n      <td>0.074543</td>\n      <td>0.095066</td>\n      <td>0.085921</td>\n      <td>0.081424</td>\n      <td>0.077734</td>\n      <td>0.093882</td>\n      <td>0.076336</td>\n      <td>0.120271</td>\n      <td>0.139008</td>\n      <td>...</td>\n      <td>0.284245</td>\n      <td>0.105763</td>\n      <td>0.081423</td>\n      <td>0.070897</td>\n      <td>0.080758</td>\n      <td>0.240842</td>\n      <td>0.075819</td>\n      <td>0.068428</td>\n      <td>0.084785</td>\n      <td>0.061514</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.124761</td>\n      <td>0.119868</td>\n      <td>0.190222</td>\n      <td>0.177617</td>\n      <td>0.157294</td>\n      <td>0.158628</td>\n      <td>0.168228</td>\n      <td>0.168455</td>\n      <td>0.192616</td>\n      <td>0.183971</td>\n      <td>...</td>\n      <td>0.254718</td>\n      <td>0.197059</td>\n      <td>0.150857</td>\n      <td>0.139093</td>\n      <td>0.142268</td>\n      <td>0.313414</td>\n      <td>0.152301</td>\n      <td>0.136795</td>\n      <td>0.161222</td>\n      <td>0.132984</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.065831</td>\n      <td>...</td>\n      <td>0.245803</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.052837</td>\n      <td>0.122746</td>\n      <td>0.113759</td>\n      <td>0.091760</td>\n      <td>0.114470</td>\n      <td>0.098803</td>\n      <td>0.140322</td>\n      <td>0.056671</td>\n      <td>0.186142</td>\n      <td>0.230169</td>\n      <td>...</td>\n      <td>0.470852</td>\n      <td>0.144302</td>\n      <td>0.122473</td>\n      <td>0.103245</td>\n      <td>0.130172</td>\n      <td>0.492389</td>\n      <td>0.087407</td>\n      <td>0.088721</td>\n      <td>0.121459</td>\n      <td>0.039246</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.980876</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "# alright, let's see if I can generate anything to show for myself re: TF-IDF Vectorizer... \n",
    "\n",
    "# instantiate:\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 100, min_df= 0.25 , max_df= 0.75)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector = create_term_matrix(df_joined['text'], tfidf)\n",
    "\n",
    "df_joined_tfidfvector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       did    donald  government  house      just      like       new  news  \\\n",
       "0  0.00000  0.190346    0.000000    0.0  0.000000  0.000000  0.201783   0.0   \n",
       "1  0.15181  0.123258    0.143941    0.0  0.000000  0.142809  0.130664   0.0   \n",
       "2  0.00000  0.222543    0.000000    0.0  0.000000  0.000000  0.235915   0.0   \n",
       "3  0.00000  0.119426    0.139466    0.0  0.000000  0.000000  0.126602   0.0   \n",
       "4  0.00000  0.064380    0.075184    0.0  0.071809  0.000000  0.818984   0.0   \n",
       "\n",
       "     people  president  ...      said     state    states      time      told  \\\n",
       "0  0.000000   0.163030  ...  0.000000  0.000000  0.000000  0.432356  0.000000   \n",
       "1  0.119369   0.211139  ...  0.250194  0.271940  0.697583  0.000000  0.000000   \n",
       "2  0.000000   0.190607  ...  0.150575  0.000000  0.000000  0.000000  0.719777   \n",
       "3  0.115657   0.204575  ...  0.323220  0.131743  0.405537  0.000000  0.000000   \n",
       "4  0.000000   0.055141  ...  0.479166  0.000000  0.072873  0.219353  0.000000   \n",
       "\n",
       "      trump   united  washington      year     years  \n",
       "0  0.524103  0.00000    0.000000  0.638174  0.000000  \n",
       "1  0.113127  0.14763    0.291545  0.000000  0.000000  \n",
       "2  0.408504  0.00000    0.000000  0.000000  0.000000  \n",
       "3  0.548050  0.42912    0.141240  0.133467  0.147699  \n",
       "4  0.118178  0.07711    0.000000  0.071950  0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>0.190346</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.201783</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.163030</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.432356</td>\n      <td>0.000000</td>\n      <td>0.524103</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.638174</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.15181</td>\n      <td>0.123258</td>\n      <td>0.143941</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.142809</td>\n      <td>0.130664</td>\n      <td>0.0</td>\n      <td>0.119369</td>\n      <td>0.211139</td>\n      <td>...</td>\n      <td>0.250194</td>\n      <td>0.271940</td>\n      <td>0.697583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.113127</td>\n      <td>0.14763</td>\n      <td>0.291545</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>0.222543</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235915</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.190607</td>\n      <td>...</td>\n      <td>0.150575</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.719777</td>\n      <td>0.408504</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>0.119426</td>\n      <td>0.139466</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.126602</td>\n      <td>0.0</td>\n      <td>0.115657</td>\n      <td>0.204575</td>\n      <td>...</td>\n      <td>0.323220</td>\n      <td>0.131743</td>\n      <td>0.405537</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.548050</td>\n      <td>0.42912</td>\n      <td>0.141240</td>\n      <td>0.133467</td>\n      <td>0.147699</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>0.064380</td>\n      <td>0.075184</td>\n      <td>0.0</td>\n      <td>0.071809</td>\n      <td>0.000000</td>\n      <td>0.818984</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.055141</td>\n      <td>...</td>\n      <td>0.479166</td>\n      <td>0.000000</td>\n      <td>0.072873</td>\n      <td>0.219353</td>\n      <td>0.000000</td>\n      <td>0.118178</td>\n      <td>0.07711</td>\n      <td>0.000000</td>\n      <td>0.071950</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "df_joined_tfidfvector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42800 entries, 0 to 42799\nData columns (total 22 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   did         42800 non-null  float64\n 1   donald      42800 non-null  float64\n 2   government  42800 non-null  float64\n 3   house       42800 non-null  float64\n 4   just        42800 non-null  float64\n 5   like        42800 non-null  float64\n 6   new         42800 non-null  float64\n 7   news        42800 non-null  float64\n 8   people      42800 non-null  float64\n 9   president   42800 non-null  float64\n 10  republican  42800 non-null  float64\n 11  reuters     42800 non-null  float64\n 12  said        42800 non-null  float64\n 13  state       42800 non-null  float64\n 14  states      42800 non-null  float64\n 15  time        42800 non-null  float64\n 16  told        42800 non-null  float64\n 17  trump       42800 non-null  float64\n 18  united      42800 non-null  float64\n 19  washington  42800 non-null  float64\n 20  year        42800 non-null  float64\n 21  years       42800 non-null  float64\ndtypes: float64(22)\nmemory usage: 7.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_joined_tfidfvector.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline\n",
    "# model = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(lowercase=True, ngram_range=(1,1))),\n",
    "#     ('dim_red', TruncatedSVD(n_components=50, random_state=42)),\n",
    "#     ('predictor', GradientBoostingClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Fit model to training data\n",
    "# model.fit(X_train, y_train); \n",
    "\n",
    "# REMEMBER TO GET A VALIDATION SPLIT AND CHECK IT AGAINST THAT. "
   ]
  }
 ]
}