{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our preamble cell :\n",
    "# remember to check for anything missing \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real data shape:  (21417, 5)\n",
      "Fake data shape:  (23481, 5)\n"
     ]
    }
   ],
   "source": [
    "# OK, importing and minor cleaning first. \n",
    "\n",
    "dfreal = pd.read_csv('True.csv',\n",
    "                    parse_dates = ['date'])\n",
    "                    #index_col = 'date')\n",
    "dfreal['Fake'] = 0\n",
    "print('Real data shape: ', dfreal.shape)\n",
    "\n",
    "dffake = pd.read_csv('Fake.csv',\n",
    "                    parse_dates = ['date'])\n",
    "                    #index_col = 'date')\n",
    "\n",
    "dffake['Fake'] = 1\n",
    "print('Fake data shape: ', dffake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real trimmed shape:  (21400, 5)\nFake trimmed shape:  (21400, 5)\n\nCombined and trimmed (equal parts Real and Fake) shape:  (42800, 5)\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump on Twitter (Dec 26) - Hillary Clinton, T...   \n",
       "1  U.S. appeals court rejects challenge to Trump ...   \n",
       "2  Treasury Secretary Mnuchin was sent gift-wrapp...   \n",
       "3  Federal judge partially lifts Trump's latest r...   \n",
       "4  Exclusive: U.S. memo weakens guidelines for pr...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  The following statements were posted to the ve...  politicsNews   \n",
       "1  (Reuters) - A U.S. appeals court in Washington...  politicsNews   \n",
       "2  (Reuters) - A gift-wrapped package addressed t...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - A federal judge in Seat...  politicsNews   \n",
       "4  NEW YORK (Reuters) - The U.S. Justice Departme...  politicsNews   \n",
       "\n",
       "                  date  Fake  \n",
       "0  2017-12-26 00:00:00     0  \n",
       "1  2017-12-26 00:00:00     0  \n",
       "2  2017-12-24 00:00:00     0  \n",
       "3  2017-12-24 00:00:00     0  \n",
       "4  2017-12-23 00:00:00     0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>Fake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump on Twitter (Dec 26) - Hillary Clinton, T...</td>\n      <td>The following statements were posted to the ve...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. appeals court rejects challenge to Trump ...</td>\n      <td>(Reuters) - A U.S. appeals court in Washington...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Treasury Secretary Mnuchin was sent gift-wrapp...</td>\n      <td>(Reuters) - A gift-wrapped package addressed t...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Federal judge partially lifts Trump's latest r...</td>\n      <td>WASHINGTON (Reuters) - A federal judge in Seat...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Exclusive: U.S. memo weakens guidelines for pr...</td>\n      <td>NEW YORK (Reuters) - The U.S. Justice Departme...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23 00:00:00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# now I'll trim those up so they are the same length - \n",
    "# 50% real 50% fake seems reasonable right?\n",
    "\n",
    "dfreal_trimmed = dfreal[-21_400 :]\n",
    "print('Real trimmed shape: ', dfreal_trimmed.shape)\n",
    "\n",
    "dffake_trimmed = dffake[-21_400 :]\n",
    "print('Fake trimmed shape: ', dffake_trimmed.shape)\n",
    "\n",
    "# and now combine them into one dataframe:\n",
    "df_joined = dfreal_trimmed.append(dffake_trimmed, ignore_index=True)\n",
    "print()\n",
    "print('Combined and trimmed (equal parts Real and Fake) shape: ', df_joined.shape)\n",
    "print()\n",
    "#print(df_joined.head(1))\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    21400\n",
       "1    21400\n",
       "Name: Fake, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_joined['Fake'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline : 0.5\n"
     ]
    }
   ],
   "source": [
    "# this is silly but it's good form, so here's a baseline. \n",
    "print('Baseline :', df_joined['Fake'].value_counts().max()/len(df_joined['Fake']))"
   ]
  },
  {
   "source": [
    "# I don't think we'll use this but here's a Count Vectorizer just in case:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          according      american        called      campaign       clinton  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.314860      0.360047      0.295864      0.483551      0.617967   \n",
       "std        0.787661      1.064934      0.659172      1.348366      2.304393   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       20.000000     48.000000     10.000000     31.000000     67.000000   \n",
       "\n",
       "            country         court    democratic           did        donald  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.389182      0.329229      0.303621      0.369579      0.589720   \n",
       "std        0.904831      1.352565      0.888218      0.797904      1.019764   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max       26.000000     43.000000     18.000000     20.000000     32.000000   \n",
       "\n",
       "       ...       support          time          told         trump  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.297453      0.460584      0.529463      2.516986   \n",
       "std    ...      0.767365      0.909996      0.939871      4.381324   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      1.000000      1.000000      3.000000   \n",
       "max    ...     24.000000     28.000000     13.000000     73.000000   \n",
       "\n",
       "             united    washington          week         white          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.536192      0.421916      0.299743      0.482874      0.557079   \n",
       "std        1.283519      0.954844      0.675265      1.305999      1.120036   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max       42.000000     35.000000     10.000000     36.000000     27.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.386706  \n",
       "std        0.890860  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max       61.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>according</th>\n      <th>american</th>\n      <th>called</th>\n      <th>campaign</th>\n      <th>clinton</th>\n      <th>country</th>\n      <th>court</th>\n      <th>democratic</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>...</th>\n      <th>support</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>week</th>\n      <th>white</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.314860</td>\n      <td>0.360047</td>\n      <td>0.295864</td>\n      <td>0.483551</td>\n      <td>0.617967</td>\n      <td>0.389182</td>\n      <td>0.329229</td>\n      <td>0.303621</td>\n      <td>0.369579</td>\n      <td>0.589720</td>\n      <td>...</td>\n      <td>0.297453</td>\n      <td>0.460584</td>\n      <td>0.529463</td>\n      <td>2.516986</td>\n      <td>0.536192</td>\n      <td>0.421916</td>\n      <td>0.299743</td>\n      <td>0.482874</td>\n      <td>0.557079</td>\n      <td>0.386706</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.787661</td>\n      <td>1.064934</td>\n      <td>0.659172</td>\n      <td>1.348366</td>\n      <td>2.304393</td>\n      <td>0.904831</td>\n      <td>1.352565</td>\n      <td>0.888218</td>\n      <td>0.797904</td>\n      <td>1.019764</td>\n      <td>...</td>\n      <td>0.767365</td>\n      <td>0.909996</td>\n      <td>0.939871</td>\n      <td>4.381324</td>\n      <td>1.283519</td>\n      <td>0.954844</td>\n      <td>0.675265</td>\n      <td>1.305999</td>\n      <td>1.120036</td>\n      <td>0.890860</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20.000000</td>\n      <td>48.000000</td>\n      <td>10.000000</td>\n      <td>31.000000</td>\n      <td>67.000000</td>\n      <td>26.000000</td>\n      <td>43.000000</td>\n      <td>18.000000</td>\n      <td>20.000000</td>\n      <td>32.000000</td>\n      <td>...</td>\n      <td>24.000000</td>\n      <td>28.000000</td>\n      <td>13.000000</td>\n      <td>73.000000</td>\n      <td>42.000000</td>\n      <td>35.000000</td>\n      <td>10.000000</td>\n      <td>36.000000</td>\n      <td>27.000000</td>\n      <td>61.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# instantiate the count vectorizer:\n",
    "cv = CountVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, max_df = 0.95 , min_df = 0.01 )\n",
    "\n",
    "# here's a function to return a dataframe:\n",
    "\n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "# now here's the actual \"thing\":\n",
    "\n",
    "df_joined_CountVector = create_term_matrix(df_joined['text'], cv)\n",
    "\n",
    "df_joined_CountVector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after reading today, it would appear that the results of the Tf-IDF Vectorizer are the same results are doing a Count Vectorizer followed by a Tf-IDF Transform. \n",
    "# Everyone I spoke to from lambda seemed to think the only model I should run here is probably the GradientBoostingClassifier. \n",
    "# I've been reading documentation on how to adjust TF-IDF Vectorizer.\n",
    "# I still have questions regarding how to merge the results from this with my orginal df_joined(41,800 x 5) - so pin in that for now. \n",
    "\n",
    "# finally got git bash working with my github repo - big shoutout to Jacob Maxfield and Josh Carlisle. \n",
    "# getting a bit confused by pipenv install not working with the nltk package - don't need it for this though, maybe anaconda later... \n",
    "# create a dictionary for myself (ex: year and years same word) - (sisichen)\n",
    "# find an NLP function that can cluster similiar words together - lookup common NLP functions - (sisichen)\n",
    "# merging original frame and target vector with results so that I can train test split and fit model...\n",
    "# Ngrams. need to grok that. sequences of words, but how many and in what order??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                did        donald    government        house          just  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.00000  42800.000000   \n",
       "mean       0.057976      0.074466      0.095030      0.08585      0.081363   \n",
       "std        0.124791      0.119814      0.190170      0.17762      0.157345   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%        0.052583      0.122620      0.113733      0.09145      0.114226   \n",
       "max        1.000000      1.000000      1.000000      1.00000      1.000000   \n",
       "\n",
       "               like           new          news        people     president  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.077764      0.093913      0.076367      0.120285      0.138979   \n",
       "std        0.158730      0.168262      0.168511      0.192650      0.183979   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.065588   \n",
       "75%        0.098738      0.140378      0.056638      0.186211      0.230136   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...          said         state        states          time  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.284218      0.105809      0.081443      0.070904   \n",
       "std    ...      0.254732      0.197131      0.150900      0.139149   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.245756      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.470876      0.144329      0.122476      0.103186   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               told         trump        united    washington          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.080791      0.240466      0.075833      0.068417      0.084779   \n",
       "std        0.142332      0.313201      0.152335      0.136781      0.161208   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.130166      0.491378      0.087378      0.088731      0.121411   \n",
       "max        1.000000      1.000000      0.980872      1.000000      1.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.061547  \n",
       "std        0.133028  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.039868  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.00000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.057976</td>\n      <td>0.074466</td>\n      <td>0.095030</td>\n      <td>0.08585</td>\n      <td>0.081363</td>\n      <td>0.077764</td>\n      <td>0.093913</td>\n      <td>0.076367</td>\n      <td>0.120285</td>\n      <td>0.138979</td>\n      <td>...</td>\n      <td>0.284218</td>\n      <td>0.105809</td>\n      <td>0.081443</td>\n      <td>0.070904</td>\n      <td>0.080791</td>\n      <td>0.240466</td>\n      <td>0.075833</td>\n      <td>0.068417</td>\n      <td>0.084779</td>\n      <td>0.061547</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.124791</td>\n      <td>0.119814</td>\n      <td>0.190170</td>\n      <td>0.17762</td>\n      <td>0.157345</td>\n      <td>0.158730</td>\n      <td>0.168262</td>\n      <td>0.168511</td>\n      <td>0.192650</td>\n      <td>0.183979</td>\n      <td>...</td>\n      <td>0.254732</td>\n      <td>0.197131</td>\n      <td>0.150900</td>\n      <td>0.139149</td>\n      <td>0.142332</td>\n      <td>0.313201</td>\n      <td>0.152335</td>\n      <td>0.136781</td>\n      <td>0.161208</td>\n      <td>0.133028</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.065588</td>\n      <td>...</td>\n      <td>0.245756</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.052583</td>\n      <td>0.122620</td>\n      <td>0.113733</td>\n      <td>0.09145</td>\n      <td>0.114226</td>\n      <td>0.098738</td>\n      <td>0.140378</td>\n      <td>0.056638</td>\n      <td>0.186211</td>\n      <td>0.230136</td>\n      <td>...</td>\n      <td>0.470876</td>\n      <td>0.144329</td>\n      <td>0.122476</td>\n      <td>0.103186</td>\n      <td>0.130166</td>\n      <td>0.491378</td>\n      <td>0.087378</td>\n      <td>0.088731</td>\n      <td>0.121411</td>\n      <td>0.039868</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.980872</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# alright, let's see if I can generate anything to show for myself re: TF-IDF Vectorizer... \n",
    "\n",
    "# instantiate:\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 100, min_df= 0.25 , max_df= 0.75)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector = create_term_matrix(df_joined['text'], tfidf)\n",
    "\n",
    "df_joined_tfidfvector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        did    donald  government  house      just      like       new  news  \\\n",
       "0  0.000000  0.190417    0.000000    0.0  0.000000  0.000000  0.201728   0.0   \n",
       "1  0.151817  0.123320    0.143931    0.0  0.000000  0.142834  0.130646   0.0   \n",
       "2  0.000000  0.222648    0.000000    0.0  0.000000  0.000000  0.235874   0.0   \n",
       "3  0.000000  0.119469    0.139435    0.0  0.000000  0.000000  0.126565   0.0   \n",
       "4  0.000000  0.064417    0.075183    0.0  0.071857  0.000000  0.818922   0.0   \n",
       "\n",
       "     people  president  ...      said     state    states      time      told  \\\n",
       "0  0.000000   0.163035  ...  0.000000  0.000000  0.000000  0.432390  0.000000   \n",
       "1  0.119388   0.211174  ...  0.250203  0.271883  0.697557  0.000000  0.000000   \n",
       "2  0.000000   0.190631  ...  0.150576  0.000000  0.000000  0.000000  0.719675   \n",
       "3  0.115659   0.204578  ...  0.323185  0.131696  0.405462  0.000000  0.000000   \n",
       "4  0.000000   0.055154  ...  0.479215  0.000000  0.072874  0.219412  0.000000   \n",
       "\n",
       "      trump    united  washington      year    years  \n",
       "0  0.524292  0.000000    0.000000  0.638001  0.00000  \n",
       "1  0.113183  0.147631    0.291535  0.000000  0.00000  \n",
       "2  0.408690  0.000000    0.000000  0.000000  0.00000  \n",
       "3  0.548239  0.429059    0.141215  0.133428  0.14765  \n",
       "4  0.118243  0.077116    0.000000  0.071944  0.00000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.190417</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.201728</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.163035</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.432390</td>\n      <td>0.000000</td>\n      <td>0.524292</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.638001</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.151817</td>\n      <td>0.123320</td>\n      <td>0.143931</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.142834</td>\n      <td>0.130646</td>\n      <td>0.0</td>\n      <td>0.119388</td>\n      <td>0.211174</td>\n      <td>...</td>\n      <td>0.250203</td>\n      <td>0.271883</td>\n      <td>0.697557</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.113183</td>\n      <td>0.147631</td>\n      <td>0.291535</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.222648</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235874</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.190631</td>\n      <td>...</td>\n      <td>0.150576</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.719675</td>\n      <td>0.408690</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.119469</td>\n      <td>0.139435</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.126565</td>\n      <td>0.0</td>\n      <td>0.115659</td>\n      <td>0.204578</td>\n      <td>...</td>\n      <td>0.323185</td>\n      <td>0.131696</td>\n      <td>0.405462</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.548239</td>\n      <td>0.429059</td>\n      <td>0.141215</td>\n      <td>0.133428</td>\n      <td>0.14765</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.064417</td>\n      <td>0.075183</td>\n      <td>0.0</td>\n      <td>0.071857</td>\n      <td>0.000000</td>\n      <td>0.818922</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.055154</td>\n      <td>...</td>\n      <td>0.479215</td>\n      <td>0.000000</td>\n      <td>0.072874</td>\n      <td>0.219412</td>\n      <td>0.000000</td>\n      <td>0.118243</td>\n      <td>0.077116</td>\n      <td>0.000000</td>\n      <td>0.071944</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_joined_tfidfvector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok. in all honesty, I'm relieved that the same params apply to tf-idf vectorizer. Now i just need to dial them in and figure out what this model needs. "
   ]
  }
 ]
}