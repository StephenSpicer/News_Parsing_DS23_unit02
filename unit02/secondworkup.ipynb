{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our preamble cell :\n",
    "# remember to check for anything missing \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real data shape:  (21417, 5)\n",
      "Fake data shape:  (23481, 5)\n"
     ]
    }
   ],
   "source": [
    "# OK, importing and minor cleaning first. \n",
    "\n",
    "dfreal = pd.read_csv('True.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "dfreal['Fake'] = 0\n",
    "print('Real data shape: ', dfreal.shape)\n",
    "\n",
    "dffake = pd.read_csv('Fake.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "\n",
    "dffake['Fake'] = 1\n",
    "print('Fake data shape: ', dffake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20    182\n",
       "2017-12-06    166\n",
       "2017-11-30    162\n",
       "2017-11-09    158\n",
       "2017-10-13    155\n",
       "             ... \n",
       "2016-09-11      1\n",
       "2016-05-14      1\n",
       "2016-05-30      1\n",
       "2016-08-06      1\n",
       "2016-09-03      1\n",
       "Name: date, Length: 716, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# this is proof that only the fake csv has garbage dates in it, which is why none of the parse dates worked. \n",
    "dfreal['date'].value_counts()\n",
    "#.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "May 10, 2017                                                                                                                                             46\n",
       "May 5, 2016                                                                                                                                              44\n",
       "May 26, 2016                                                                                                                                             44\n",
       "May 6, 2016                                                                                                                                              44\n",
       "May 11, 2016                                                                                                                                             43\n",
       "                                                                                                                                                         ..\n",
       "November 20, 2017                                                                                                                                         1\n",
       "November 19, 2017                                                                                                                                         1\n",
       "https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/     1\n",
       "October 9, 2017                                                                                                                                           1\n",
       "Jul 19, 2015                                                                                                                                              1\n",
       "Name: date, Length: 1681, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "dffake['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(23481, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "\n",
    "# dffake = \n",
    "comma_list = pd.DataFrame(dffake['date'].str.find(','))\n",
    "\n",
    "comma_list.value_counts()\n",
    "comma_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~df['your column'].isin(['list of strings'])]\n",
    "# http = ['http',\".com\"]\n",
    "# dffake2 = dffake[~dffake.date.isin(http)]\n",
    "\n",
    "searchfor = ['http', '-', 'MSNBC']\n",
    "dffake2 = dffake[~dffake['date'].str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "May 10, 2017         46\n",
       "May 26, 2016         44\n",
       "May 6, 2016          44\n",
       "May 5, 2016          44\n",
       "May 11, 2016         43\n",
       "                     ..\n",
       "October 9, 2017       1\n",
       "December 19, 2017     1\n",
       "November 19, 2017     1\n",
       "October 22, 2017      1\n",
       "December 9, 2017      1\n",
       "Name: date, Length: 1669, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "dffake2['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(23436, 5)\n(21417, 5)\n"
     ]
    }
   ],
   "source": [
    "print(dffake2.shape)\n",
    "print(dfreal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dffake2['date'] = pd.to_datetime(dffake2['date'], format='%m%d%y')\n",
    "# dffake2['date'] = dffake2['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real trimmed shape:  (21400, 5)\nFake trimmed shape:  (21400, 5)\n\nCombined and trimmed (equal parts Real and Fake) shape:  (42800, 5)\n\n"
     ]
    }
   ],
   "source": [
    "# now I'll trim those up so they are the same length - \n",
    "# 50% real 50% fake seems reasonable right?\n",
    "\n",
    "dfreal_trimmed = dfreal[-21_400 :]\n",
    "print('Real trimmed shape: ', dfreal_trimmed.shape)\n",
    "\n",
    "dffake_trimmed = dffake2[-21_400 :]\n",
    "print('Fake trimmed shape: ', dffake_trimmed.shape)\n",
    "\n",
    "# and now combine them into one dataframe:\n",
    "df_joined = dfreal_trimmed.append(dffake_trimmed, ignore_index=True)\n",
    "\n",
    "df_joined['date'] = pd.to_datetime(df_joined['date'])\n",
    "\n",
    "print()\n",
    "print('Combined and trimmed (equal parts Real and Fake) shape: ', df_joined.shape)\n",
    "print()\n",
    "#print(df_joined.head(1))\n",
    "#df_joined.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20    194\n",
       "2017-12-06    180\n",
       "2017-11-09    178\n",
       "2017-11-30    175\n",
       "2017-10-13    171\n",
       "             ... \n",
       "2015-06-21      1\n",
       "2015-06-07      1\n",
       "2015-07-19      1\n",
       "2015-07-18      1\n",
       "2015-04-02      1\n",
       "Name: date, Length: 1004, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "df_joined['date'].value_counts()\n",
    "\n",
    "# Holy Smokes I think all the date times are clean. \n",
    "# Let's never spend 2 days on that again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All URL's and Wrong-Dates seem to be corrected. Finally.  \n",
    "# X and y are still not the same length - need to fix that... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump on Twitter (Dec 26) - Hillary Clinton, T...   \n",
       "1  U.S. appeals court rejects challenge to Trump ...   \n",
       "2  Treasury Secretary Mnuchin was sent gift-wrapp...   \n",
       "3  Federal judge partially lifts Trump's latest r...   \n",
       "4  Exclusive: U.S. memo weakens guidelines for pr...   \n",
       "\n",
       "                                                text       subject       date  \\\n",
       "0  The following statements were posted to the ve...  politicsNews 2017-12-26   \n",
       "1  (Reuters) - A U.S. appeals court in Washington...  politicsNews 2017-12-26   \n",
       "2  (Reuters) - A gift-wrapped package addressed t...  politicsNews 2017-12-24   \n",
       "3  WASHINGTON (Reuters) - A federal judge in Seat...  politicsNews 2017-12-24   \n",
       "4  NEW YORK (Reuters) - The U.S. Justice Departme...  politicsNews 2017-12-23   \n",
       "\n",
       "   Fake  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>Fake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump on Twitter (Dec 26) - Hillary Clinton, T...</td>\n      <td>The following statements were posted to the ve...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. appeals court rejects challenge to Trump ...</td>\n      <td>(Reuters) - A U.S. appeals court in Washington...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Treasury Secretary Mnuchin was sent gift-wrapp...</td>\n      <td>(Reuters) - A gift-wrapped package addressed t...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Federal judge partially lifts Trump's latest r...</td>\n      <td>WASHINGTON (Reuters) - A federal judge in Seat...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Exclusive: U.S. memo weakens guidelines for pr...</td>\n      <td>NEW YORK (Reuters) - The U.S. Justice Departme...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "df_joined.head()"
   ]
  },
  {
   "source": [
    "## *I don't think we'll use this but here's a Count Vectorizer just in case:*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          according      american        called      campaign       clinton  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.315047      0.360117      0.295794      0.483505      0.618014   \n",
       "std        0.787854      1.065031      0.658973      1.347394      2.304309   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       20.000000     48.000000     10.000000     31.000000     67.000000   \n",
       "\n",
       "            country         court    democratic           did        donald  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.389159      0.329299      0.303575      0.369673      0.590771   \n",
       "std        0.904674      1.353023      0.888128      0.797977      1.020930   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max       26.000000     43.000000     18.000000     20.000000     32.000000   \n",
       "\n",
       "       ...       support          time          told         trump  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.297734      0.460935      0.529416      2.523014   \n",
       "std    ...      0.768017      0.910293      0.939773      4.386813   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      1.000000      1.000000      3.000000   \n",
       "max    ...     24.000000     28.000000     13.000000     73.000000   \n",
       "\n",
       "             united    washington          week         white          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.536028      0.422009      0.299813      0.483178      0.557126   \n",
       "std        1.283105      0.954925      0.675320      1.305252      1.120097   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max       42.000000     35.000000     10.000000     36.000000     27.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.386589  \n",
       "std        0.890714  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max       61.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>according</th>\n      <th>american</th>\n      <th>called</th>\n      <th>campaign</th>\n      <th>clinton</th>\n      <th>country</th>\n      <th>court</th>\n      <th>democratic</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>...</th>\n      <th>support</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>week</th>\n      <th>white</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.315047</td>\n      <td>0.360117</td>\n      <td>0.295794</td>\n      <td>0.483505</td>\n      <td>0.618014</td>\n      <td>0.389159</td>\n      <td>0.329299</td>\n      <td>0.303575</td>\n      <td>0.369673</td>\n      <td>0.590771</td>\n      <td>...</td>\n      <td>0.297734</td>\n      <td>0.460935</td>\n      <td>0.529416</td>\n      <td>2.523014</td>\n      <td>0.536028</td>\n      <td>0.422009</td>\n      <td>0.299813</td>\n      <td>0.483178</td>\n      <td>0.557126</td>\n      <td>0.386589</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.787854</td>\n      <td>1.065031</td>\n      <td>0.658973</td>\n      <td>1.347394</td>\n      <td>2.304309</td>\n      <td>0.904674</td>\n      <td>1.353023</td>\n      <td>0.888128</td>\n      <td>0.797977</td>\n      <td>1.020930</td>\n      <td>...</td>\n      <td>0.768017</td>\n      <td>0.910293</td>\n      <td>0.939773</td>\n      <td>4.386813</td>\n      <td>1.283105</td>\n      <td>0.954925</td>\n      <td>0.675320</td>\n      <td>1.305252</td>\n      <td>1.120097</td>\n      <td>0.890714</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20.000000</td>\n      <td>48.000000</td>\n      <td>10.000000</td>\n      <td>31.000000</td>\n      <td>67.000000</td>\n      <td>26.000000</td>\n      <td>43.000000</td>\n      <td>18.000000</td>\n      <td>20.000000</td>\n      <td>32.000000</td>\n      <td>...</td>\n      <td>24.000000</td>\n      <td>28.000000</td>\n      <td>13.000000</td>\n      <td>73.000000</td>\n      <td>42.000000</td>\n      <td>35.000000</td>\n      <td>10.000000</td>\n      <td>36.000000</td>\n      <td>27.000000</td>\n      <td>61.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "# instantiate the count vectorizer:\n",
    "cv = CountVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, max_df = 0.95 , min_df = 0.01 )\n",
    "\n",
    "# here's a function to return a dataframe:\n",
    "\n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "# now here's the actual \"thing\":\n",
    "\n",
    "df_joined_CountVector = create_term_matrix(df_joined['text'], cv)\n",
    "\n",
    "df_joined_CountVector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-IDF Vectorizer are the same results are doing a Count Vectorizer followed by a Tf-IDF Transform. \n",
    "# GradientBoostingClassifier. Good thing we learned some params today. \n",
    "# \n",
    "# I still have questions regarding how to merge the results from this with my orginal df_joined(41,800 x 5) - so pin in that for now. \n",
    "\n",
    "# \n",
    "# create a dictionary for myself (ex: year and years same word) - (sisichen)\n",
    "# find an NLP function that can cluster similiar words together - lookup common NLP functions - (sisichen)\n",
    "\n",
    "# merging original frame and target vector with results so that I can train test split and fit model...\n",
    "# Ngrams. They exist in the parameters for the vectorizer / model below... "
   ]
  },
  {
   "source": [
    "## *now for TF-IDF* - check for class weight = balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42800 entries, 0 to 42799\nData columns (total 22 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   did         42800 non-null  float64\n 1   donald      42800 non-null  float64\n 2   government  42800 non-null  float64\n 3   house       42800 non-null  float64\n 4   just        42800 non-null  float64\n 5   like        42800 non-null  float64\n 6   new         42800 non-null  float64\n 7   news        42800 non-null  float64\n 8   people      42800 non-null  float64\n 9   president   42800 non-null  float64\n 10  republican  42800 non-null  float64\n 11  reuters     42800 non-null  float64\n 12  said        42800 non-null  float64\n 13  state       42800 non-null  float64\n 14  states      42800 non-null  float64\n 15  time        42800 non-null  float64\n 16  told        42800 non-null  float64\n 17  trump       42800 non-null  float64\n 18  united      42800 non-null  float64\n 19  washington  42800 non-null  float64\n 20  year        42800 non-null  float64\n 21  years       42800 non-null  float64\ndtypes: float64(22)\nmemory usage: 7.2 MB\n"
     ]
    }
   ],
   "source": [
    "# alright, let's see if I can generate anything to show for myself re: TF-IDF Vectorizer... \n",
    "\n",
    "# instantiate:\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, min_df= 0.25 , max_df= 0.75)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "joined_tfid01 = create_term_matrix(df_joined['text'], tfidf)\n",
    "\n",
    "joined_tfid01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42800, 22)\n"
     ]
    }
   ],
   "source": [
    "# ok an attempt to get it back into the original frame so we can train test split... \n",
    "\n",
    "#df_joined_tfidvect = df_joined \n",
    "#df_joined_tfidvect['tfidf'] \n",
    "\n",
    "#first drop text\n",
    "df_joined_tfidvect = df_joined.drop(['text'], axis=1)\n",
    "\n",
    "#fit it - sparse series\n",
    "tfidf_fit = tfidf.fit_transform(df_joined['text'])\n",
    "print(tfidf_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42800, 27)"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "source": [
    "#dataframe (temporary, using pd.DataFrame and .toarray)\n",
    "df1 = pd.DataFrame(tfidf_fit.toarray(), columns=tfidf.get_feature_names())\n",
    "\n",
    "\n",
    "#concat (after drop) for resulting frame\n",
    "df_joined_tfidvect = pd.concat([df_joined_tfidvect, df1], axis=1)\n",
    "\n",
    "df_joined_tfidvect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title       subject       date  \\\n",
       "0  Trump on Twitter (Dec 26) - Hillary Clinton, T...  politicsNews 2017-12-26   \n",
       "1  U.S. appeals court rejects challenge to Trump ...  politicsNews 2017-12-26   \n",
       "2  Treasury Secretary Mnuchin was sent gift-wrapp...  politicsNews 2017-12-24   \n",
       "3  Federal judge partially lifts Trump's latest r...  politicsNews 2017-12-24   \n",
       "4  Exclusive: U.S. memo weakens guidelines for pr...  politicsNews 2017-12-23   \n",
       "\n",
       "   Fake                                              tfidf      did    donald  \\\n",
       "0     0    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.190346   \n",
       "1     0    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.15181  0.123258   \n",
       "2     0    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.222543   \n",
       "3     0    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.119426   \n",
       "4     0    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.064380   \n",
       "\n",
       "   government  house      just  ...      said     state    states      time  \\\n",
       "0    0.000000    0.0  0.000000  ...  0.000000  0.000000  0.000000  0.432356   \n",
       "1    0.143941    0.0  0.000000  ...  0.250194  0.271940  0.697583  0.000000   \n",
       "2    0.000000    0.0  0.000000  ...  0.150575  0.000000  0.000000  0.000000   \n",
       "3    0.139466    0.0  0.000000  ...  0.323220  0.131743  0.405537  0.000000   \n",
       "4    0.075184    0.0  0.071809  ...  0.479166  0.000000  0.072873  0.219353   \n",
       "\n",
       "       told     trump   united  washington      year     years  \n",
       "0  0.000000  0.524103  0.00000    0.000000  0.638174  0.000000  \n",
       "1  0.000000  0.113127  0.14763    0.291545  0.000000  0.000000  \n",
       "2  0.719777  0.408504  0.00000    0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.548050  0.42912    0.141240  0.133467  0.147699  \n",
       "4  0.000000  0.118178  0.07711    0.000000  0.071950  0.000000  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>Fake</th>\n      <th>tfidf</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump on Twitter (Dec 26) - Hillary Clinton, T...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.190346</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.432356</td>\n      <td>0.000000</td>\n      <td>0.524103</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.638174</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. appeals court rejects challenge to Trump ...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.15181</td>\n      <td>0.123258</td>\n      <td>0.143941</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.250194</td>\n      <td>0.271940</td>\n      <td>0.697583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.113127</td>\n      <td>0.14763</td>\n      <td>0.291545</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Treasury Secretary Mnuchin was sent gift-wrapp...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.222543</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.150575</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.719777</td>\n      <td>0.408504</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Federal judge partially lifts Trump's latest r...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.119426</td>\n      <td>0.139466</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.323220</td>\n      <td>0.131743</td>\n      <td>0.405537</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.548050</td>\n      <td>0.42912</td>\n      <td>0.141240</td>\n      <td>0.133467</td>\n      <td>0.147699</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Exclusive: U.S. memo weakens guidelines for pr...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.064380</td>\n      <td>0.075184</td>\n      <td>0.0</td>\n      <td>0.071809</td>\n      <td>...</td>\n      <td>0.479166</td>\n      <td>0.000000</td>\n      <td>0.072873</td>\n      <td>0.219353</td>\n      <td>0.000000</td>\n      <td>0.118178</td>\n      <td>0.07711</td>\n      <td>0.000000</td>\n      <td>0.071950</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "df_joined_tfidvect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        subject  date  Fake  \\\n",
       "0  politicsNews  2017     0   \n",
       "1  politicsNews  2017     0   \n",
       "2  politicsNews  2017     0   \n",
       "3  politicsNews  2017     0   \n",
       "4  politicsNews  2017     0   \n",
       "\n",
       "                                               tfidf      did    donald  \\\n",
       "0    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.190346   \n",
       "1    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.15181  0.123258   \n",
       "2    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.222543   \n",
       "3    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.119426   \n",
       "4    (0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...  0.00000  0.064380   \n",
       "\n",
       "   government  house      just      like  ...      said     state    states  \\\n",
       "0    0.000000    0.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1    0.143941    0.0  0.000000  0.142809  ...  0.250194  0.271940  0.697583   \n",
       "2    0.000000    0.0  0.000000  0.000000  ...  0.150575  0.000000  0.000000   \n",
       "3    0.139466    0.0  0.000000  0.000000  ...  0.323220  0.131743  0.405537   \n",
       "4    0.075184    0.0  0.071809  0.000000  ...  0.479166  0.000000  0.072873   \n",
       "\n",
       "       time      told     trump   united  washington      year     years  \n",
       "0  0.432356  0.000000  0.524103  0.00000    0.000000  0.638174  0.000000  \n",
       "1  0.000000  0.000000  0.113127  0.14763    0.291545  0.000000  0.000000  \n",
       "2  0.000000  0.719777  0.408504  0.00000    0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.548050  0.42912    0.141240  0.133467  0.147699  \n",
       "4  0.219353  0.000000  0.118178  0.07711    0.000000  0.071950  0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>date</th>\n      <th>Fake</th>\n      <th>tfidf</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>politicsNews</td>\n      <td>2017</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.190346</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.432356</td>\n      <td>0.000000</td>\n      <td>0.524103</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.638174</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>politicsNews</td>\n      <td>2017</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.15181</td>\n      <td>0.123258</td>\n      <td>0.143941</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.142809</td>\n      <td>...</td>\n      <td>0.250194</td>\n      <td>0.271940</td>\n      <td>0.697583</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.113127</td>\n      <td>0.14763</td>\n      <td>0.291545</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>politicsNews</td>\n      <td>2017</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.222543</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.150575</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.719777</td>\n      <td>0.408504</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>politicsNews</td>\n      <td>2017</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.119426</td>\n      <td>0.139466</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.323220</td>\n      <td>0.131743</td>\n      <td>0.405537</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.548050</td>\n      <td>0.42912</td>\n      <td>0.141240</td>\n      <td>0.133467</td>\n      <td>0.147699</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>politicsNews</td>\n      <td>2017</td>\n      <td>0</td>\n      <td>(0, 20)\\t0.6381743283166692\\n  (0, 6)\\t0.201...</td>\n      <td>0.00000</td>\n      <td>0.064380</td>\n      <td>0.075184</td>\n      <td>0.0</td>\n      <td>0.071809</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.479166</td>\n      <td>0.000000</td>\n      <td>0.072873</td>\n      <td>0.219353</td>\n      <td>0.000000</td>\n      <td>0.118178</td>\n      <td>0.07711</td>\n      <td>0.000000</td>\n      <td>0.071950</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "source": [
    "#df_joined_tfidvect.drop(['title'], axis=1, inplace=True)\n",
    "\n",
    "df_joined_tfidvect['date'] = df_joined_tfidvect['date'].dt.year\n",
    "\n",
    "df_joined_tfidvect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:  (42800, 25)\ny shape:  (42800,)\n"
     ]
    }
   ],
   "source": [
    "# ok, that's new for us... let's gooooooo\n",
    "\n",
    "# X and y split\n",
    "\n",
    "\n",
    "\n",
    "target = df_joined_tfidvect['Fake']\n",
    "\n",
    "X = df_joined_tfidvect.drop(['Fake'], axis=1)\n",
    "\n",
    "y = target\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline : 0.5\n"
     ]
    }
   ],
   "source": [
    "# this is silly but it's good form, so here's a baseline. \n",
    "print('Baseline :', df_joined['Fake'].value_counts().max()/len(df_joined['Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24075, 25)\n(24075,)\n(8025, 25)\n(8025,)\n(10700, 25)\n(10700,)\n"
     ]
    }
   ],
   "source": [
    "# train test split:\n",
    "\n",
    "# leaving this code here in case I set up my target wrong. \n",
    "# X = df.drop(['target'],axis=1).values   # independant features\n",
    "# y = df['target'].values\t\t\t\t\t# dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# doing 25/75 split and 42. \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instantiate 2nd: much different mix max:\n",
    "# tfidf2 = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 100, min_df= 0.5 , max_df= 0.99)\n",
    "# # ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "# def create_term_matrix(message_list, vectorizer):\n",
    "#     doc_term_df = vectorizer.fit_transform(message_list)\n",
    "#     return DataFrame(doc_term_df.toarray(),\n",
    "#                      columns=vectorizer.get_feature_names())\n",
    "\n",
    "# df_joined_tfidfvector2 = create_term_matrix(df_joined['text'], tfidf2)\n",
    "\n",
    "# df_joined_tfidfvector2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   according  american    called  campaign   country       did    donald  \\\n",
       "0   0.000000       0.0  0.000000  0.498824  0.000000  0.000000  0.192121   \n",
       "1   0.000000       0.0  0.000000  0.000000  0.000000  0.143514  0.116522   \n",
       "2   0.331001       0.0  0.000000  0.000000  0.000000  0.000000  0.249475   \n",
       "3   0.184967       0.0  0.364490  0.000000  0.348085  0.000000  0.139410   \n",
       "4   0.000000       0.0  0.090353  0.000000  0.086286  0.000000  0.069116   \n",
       "\n",
       "   election     going  government  ...    states      time      told  \\\n",
       "0  0.000000  0.259713    0.000000  ...  0.000000  0.436389  0.000000   \n",
       "1  0.301517  0.000000    0.136075  ...  0.659463  0.000000  0.000000   \n",
       "2  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.806885   \n",
       "3  0.000000  0.000000    0.162803  ...  0.473397  0.000000  0.000000   \n",
       "4  0.000000  0.093432    0.080714  ...  0.078233  0.235488  0.000000   \n",
       "\n",
       "     united  washington       way      week  white      year     years  \n",
       "0  0.000000    0.000000  0.000000  0.000000    0.0  0.644126  0.000000  \n",
       "1  0.139562    0.275613  0.000000  0.000000    0.0  0.000000  0.000000  \n",
       "2  0.000000    0.000000  0.000000  0.327407    0.0  0.000000  0.000000  \n",
       "3  0.500926    0.164874  0.187637  0.000000    0.0  0.155800  0.172414  \n",
       "4  0.082782    0.000000  0.000000  0.000000    0.0  0.077242  0.000000  \n",
       "\n",
       "[5 rows x 35 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>according</th>\n      <th>american</th>\n      <th>called</th>\n      <th>campaign</th>\n      <th>country</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>election</th>\n      <th>going</th>\n      <th>government</th>\n      <th>...</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>way</th>\n      <th>week</th>\n      <th>white</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.498824</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.192121</td>\n      <td>0.000000</td>\n      <td>0.259713</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.436389</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.644126</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.143514</td>\n      <td>0.116522</td>\n      <td>0.301517</td>\n      <td>0.000000</td>\n      <td>0.136075</td>\n      <td>...</td>\n      <td>0.659463</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.139562</td>\n      <td>0.275613</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.331001</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.249475</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.806885</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.327407</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.184967</td>\n      <td>0.0</td>\n      <td>0.364490</td>\n      <td>0.000000</td>\n      <td>0.348085</td>\n      <td>0.000000</td>\n      <td>0.139410</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.162803</td>\n      <td>...</td>\n      <td>0.473397</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500926</td>\n      <td>0.164874</td>\n      <td>0.187637</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.155800</td>\n      <td>0.172414</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.090353</td>\n      <td>0.000000</td>\n      <td>0.086286</td>\n      <td>0.000000</td>\n      <td>0.069116</td>\n      <td>0.000000</td>\n      <td>0.093432</td>\n      <td>0.080714</td>\n      <td>...</td>\n      <td>0.078233</td>\n      <td>0.235488</td>\n      <td>0.000000</td>\n      <td>0.082782</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.077242</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "# instantiate: once again, different min max. \n",
    "\n",
    "tfidf3 = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, min_df= 0.2 , max_df= 0.4)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector3 = create_term_matrix(df_joined['text'], tfidf3)\n",
    "\n",
    "df_joined_tfidfvector3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "# that should be pip installed now. \n",
    "# also pip installed plotly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24075, 25)\n(24075,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 24075 entries, 7784 to 6475\nData columns (total 25 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   subject     24075 non-null  object \n 1   date        24075 non-null  int64  \n 2   tfidf       24075 non-null  object \n 3   did         24075 non-null  float64\n 4   donald      24075 non-null  float64\n 5   government  24075 non-null  float64\n 6   house       24075 non-null  float64\n 7   just        24075 non-null  float64\n 8   like        24075 non-null  float64\n 9   new         24075 non-null  float64\n 10  news        24075 non-null  float64\n 11  people      24075 non-null  float64\n 12  president   24075 non-null  float64\n 13  republican  24075 non-null  float64\n 14  reuters     24075 non-null  float64\n 15  said        24075 non-null  float64\n 16  state       24075 non-null  float64\n 17  states      24075 non-null  float64\n 18  time        24075 non-null  float64\n 19  told        24075 non-null  float64\n 20  trump       24075 non-null  float64\n 21  united      24075 non-null  float64\n 22  washington  24075 non-null  float64\n 23  year        24075 non-null  float64\n 24  years       24075 non-null  float64\ndtypes: float64(22), int64(1), object(2)\nmemory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline\n",
    "X_train.drop(['tfidf'], axis=1, inplace=True)\n",
    "\n",
    "model1 = Pipeline([\n",
    "    #('vectorizer', TfidfVectorizer(lowercase=True, stop_words = 'english', strip_accents ='ascii', max_features = 20, ngram_range=(1,2))),\n",
    "    #('dim_red', TruncatedSVD(n_components=20, random_state=42)),\n",
    "    ('encoder', OrdinalEncoder()),\n",
    "    ('predictor', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model to training data\n",
    "model1.fit(X_train, y_train); \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[18:44:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'clf__n_estimators': 75, 'vect__max_features': 1000}\n",
      "0.996524610322128\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Lets simplify : df_joined DF (80/20) split\n",
    "\n",
    "train = df_joined.loc[:34240,:]\n",
    "test = df_joined.loc[8560:,:]\n",
    "\n",
    "# For testing \n",
    "\n",
    "y = train['Fake']\n",
    "X = train['text']\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "clf = xgb.XGBClassifier() #estimator\n",
    "clf2 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "\n",
    "# super basic parameter list for tuning\n",
    "parameters = {\n",
    "    'vect__max_features': [500, 1000],\n",
    "    'clf__n_estimators':[75, 125]}\n",
    "# create the gridsearch\n",
    "grid_search = GridSearchCV(pipe, parameters, cv= 3, n_jobs=4, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X, y) # fit the model\n",
    "\n",
    "# results\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "# lets see how it does agaisnt the test\n",
    "pred = grid_search.predict(test['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = c26_model_xgb_est10.named_steps['xgbregressor'].feature_importances_\n",
    "# features = c26X_train.columns\n",
    "# feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "# feat_imp.tail(10).plot(kind='barh')\n",
    "# plt.xlabel('Gini Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.title('Feature Importances for model_skbg');"
   ]
  }
 ]
}