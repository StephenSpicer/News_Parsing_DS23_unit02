{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our preamble cell :\n",
    "# remember to check for anything missing \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real data shape:  (21417, 5)\n",
      "Fake data shape:  (23481, 5)\n"
     ]
    }
   ],
   "source": [
    "# OK, importing and minor cleaning first. \n",
    "\n",
    "dfreal = pd.read_csv('True.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "dfreal['Fake'] = 0\n",
    "print('Real data shape: ', dfreal.shape)\n",
    "\n",
    "dffake = pd.read_csv('Fake.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "\n",
    "dffake['Fake'] = 1\n",
    "print('Fake data shape: ', dffake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real trimmed shape:  (21400, 5)\nFake trimmed shape:  (21400, 5)\n\nCombined and trimmed (equal parts Real and Fake) shape:  (42800, 5)\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                title  \\\n",
       "0   Trump on Twitter (Dec 26) - Hillary Clinton, T...   \n",
       "1   U.S. appeals court rejects challenge to Trump ...   \n",
       "2   Treasury Secretary Mnuchin was sent gift-wrapp...   \n",
       "3   Federal judge partially lifts Trump's latest r...   \n",
       "4   Exclusive: U.S. memo weakens guidelines for pr...   \n",
       "5   Trump travel ban should not apply to people wi...   \n",
       "6   Second court rejects Trump bid to stop transge...   \n",
       "7   Failed vote to oust president shakes up Peru's...   \n",
       "8   Trump signs tax, government spending bills int...   \n",
       "9   Companies have up to a year for new U.S. tax b...   \n",
       "10  Trump on Twitter (Dec 22) - Tax cut, Missile d...   \n",
       "11  Mexico to review need for tax changes after U....   \n",
       "12  Senate leader McConnell sees a more collegial ...   \n",
       "13  Alabama to certify Democrat Jones winner of Se...   \n",
       "14  McConnell happier with Trump tweets after tax ...   \n",
       "15  House panel asks Trump ex-top aide Bannon to t...   \n",
       "16  Callista Gingrich becomes Trump's envoy to pop...   \n",
       "17  As Republicans aim to ride economy to election...   \n",
       "18  Exclusive: State Department tells refugee agen...   \n",
       "19  Congress votes to avert shutdown, sends Trump ...   \n",
       "20  Factbox: Big-ticket items at center of Congres...   \n",
       "21  In victory for Trump, judge tosses suit on for...   \n",
       "22  Senate shelves disaster aid bill until next month   \n",
       "23   Trump on Twitter (Dec 21) - Tax Cuts, Home sales   \n",
       "24  House widens ethics probe to include Farenthol...   \n",
       "\n",
       "                                                 text       subject  \\\n",
       "0   The following statements were posted to the ve...  politicsNews   \n",
       "1   (Reuters) - A U.S. appeals court in Washington...  politicsNews   \n",
       "2   (Reuters) - A gift-wrapped package addressed t...  politicsNews   \n",
       "3   WASHINGTON (Reuters) - A federal judge in Seat...  politicsNews   \n",
       "4   NEW YORK (Reuters) - The U.S. Justice Departme...  politicsNews   \n",
       "5   (Reuters) - A U.S. appeals court on Friday sai...  politicsNews   \n",
       "6   WASHINGTON (Reuters) - A federal appeals court...  politicsNews   \n",
       "7   LIMA (Reuters) - Peru’s President Pedro Pablo ...  politicsNews   \n",
       "8   WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "9   WASHINGTON (Reuters) - U.S. financial regulato...  politicsNews   \n",
       "10  The following statements were posted to the ve...  politicsNews   \n",
       "11  MEXICO CITY (Reuters) - Mexico’s finance minis...  politicsNews   \n",
       "12  WASHINGTON (Reuters) - U.S. Senate Majority Le...  politicsNews   \n",
       "13  (Reuters) - Democrat Doug Jones’ surprise vict...  politicsNews   \n",
       "14  WASHINGTON (Reuters) - A summer spat between P...  politicsNews   \n",
       "15  WASHINGTON (Reuters) - Steve Bannon, a former ...  politicsNews   \n",
       "16  VATICAN CITY (Reuters) - Callista Gingrich, wi...  politicsNews   \n",
       "17   KING OF PRUSSIA, Pennsylvania/WASHINGTON (Reu...  politicsNews   \n",
       "18  (Reuters) - The U.S. State Department has told...  politicsNews   \n",
       "19  WASHINGTON (Reuters) - The U.S. Congress on Th...  politicsNews   \n",
       "20  (Reuters) - The U.S. Congress on Thursday appr...  politicsNews   \n",
       "21  NEW YORK (Reuters) - A federal judge in New Yo...  politicsNews   \n",
       "22  WASHINGTON (Reuters) - Legislation to provide ...  politicsNews   \n",
       "23  The following statements were posted to the ve...  politicsNews   \n",
       "24  WASHINGTON (Reuters) - The ethics probe into U...  politicsNews   \n",
       "\n",
       "                   date  Fake  \n",
       "0   2017-12-26 00:00:00     0  \n",
       "1   2017-12-26 00:00:00     0  \n",
       "2   2017-12-24 00:00:00     0  \n",
       "3   2017-12-24 00:00:00     0  \n",
       "4   2017-12-23 00:00:00     0  \n",
       "5   2017-12-23 00:00:00     0  \n",
       "6   2017-12-23 00:00:00     0  \n",
       "7   2017-12-23 00:00:00     0  \n",
       "8   2017-12-22 00:00:00     0  \n",
       "9   2017-12-23 00:00:00     0  \n",
       "10  2017-12-22 00:00:00     0  \n",
       "11  2017-12-22 00:00:00     0  \n",
       "12  2017-12-22 00:00:00     0  \n",
       "13  2017-12-22 00:00:00     0  \n",
       "14  2017-12-22 00:00:00     0  \n",
       "15  2017-12-22 00:00:00     0  \n",
       "16  2017-12-22 00:00:00     0  \n",
       "17  2017-12-22 00:00:00     0  \n",
       "18  2017-12-21 00:00:00     0  \n",
       "19  2017-12-21 00:00:00     0  \n",
       "20  2017-12-21 00:00:00     0  \n",
       "21  2017-12-21 00:00:00     0  \n",
       "22  2017-12-22 00:00:00     0  \n",
       "23  2017-12-21 00:00:00     0  \n",
       "24  2017-12-21 00:00:00     0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>Fake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump on Twitter (Dec 26) - Hillary Clinton, T...</td>\n      <td>The following statements were posted to the ve...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. appeals court rejects challenge to Trump ...</td>\n      <td>(Reuters) - A U.S. appeals court in Washington...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Treasury Secretary Mnuchin was sent gift-wrapp...</td>\n      <td>(Reuters) - A gift-wrapped package addressed t...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Federal judge partially lifts Trump's latest r...</td>\n      <td>WASHINGTON (Reuters) - A federal judge in Seat...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Exclusive: U.S. memo weakens guidelines for pr...</td>\n      <td>NEW YORK (Reuters) - The U.S. Justice Departme...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Trump travel ban should not apply to people wi...</td>\n      <td>(Reuters) - A U.S. appeals court on Friday sai...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Second court rejects Trump bid to stop transge...</td>\n      <td>WASHINGTON (Reuters) - A federal appeals court...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Failed vote to oust president shakes up Peru's...</td>\n      <td>LIMA (Reuters) - Peru’s President Pedro Pablo ...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Trump signs tax, government spending bills int...</td>\n      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Companies have up to a year for new U.S. tax b...</td>\n      <td>WASHINGTON (Reuters) - U.S. financial regulato...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Trump on Twitter (Dec 22) - Tax cut, Missile d...</td>\n      <td>The following statements were posted to the ve...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Mexico to review need for tax changes after U....</td>\n      <td>MEXICO CITY (Reuters) - Mexico’s finance minis...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Senate leader McConnell sees a more collegial ...</td>\n      <td>WASHINGTON (Reuters) - U.S. Senate Majority Le...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Alabama to certify Democrat Jones winner of Se...</td>\n      <td>(Reuters) - Democrat Doug Jones’ surprise vict...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>McConnell happier with Trump tweets after tax ...</td>\n      <td>WASHINGTON (Reuters) - A summer spat between P...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>House panel asks Trump ex-top aide Bannon to t...</td>\n      <td>WASHINGTON (Reuters) - Steve Bannon, a former ...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Callista Gingrich becomes Trump's envoy to pop...</td>\n      <td>VATICAN CITY (Reuters) - Callista Gingrich, wi...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>As Republicans aim to ride economy to election...</td>\n      <td>KING OF PRUSSIA, Pennsylvania/WASHINGTON (Reu...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Exclusive: State Department tells refugee agen...</td>\n      <td>(Reuters) - The U.S. State Department has told...</td>\n      <td>politicsNews</td>\n      <td>2017-12-21 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Congress votes to avert shutdown, sends Trump ...</td>\n      <td>WASHINGTON (Reuters) - The U.S. Congress on Th...</td>\n      <td>politicsNews</td>\n      <td>2017-12-21 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Factbox: Big-ticket items at center of Congres...</td>\n      <td>(Reuters) - The U.S. Congress on Thursday appr...</td>\n      <td>politicsNews</td>\n      <td>2017-12-21 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>In victory for Trump, judge tosses suit on for...</td>\n      <td>NEW YORK (Reuters) - A federal judge in New Yo...</td>\n      <td>politicsNews</td>\n      <td>2017-12-21 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Senate shelves disaster aid bill until next month</td>\n      <td>WASHINGTON (Reuters) - Legislation to provide ...</td>\n      <td>politicsNews</td>\n      <td>2017-12-22 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Trump on Twitter (Dec 21) - Tax Cuts, Home sales</td>\n      <td>The following statements were posted to the ve...</td>\n      <td>politicsNews</td>\n      <td>2017-12-21 00:00:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>House widens ethics probe to include Farenthol...</td>\n      <td>WASHINGTON (Reuters) - The ethics probe into U...</td>\n      <td>politicsNews</td>\n      <td>2017-12-21 00:00:00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# now I'll trim those up so they are the same length - \n",
    "# 50% real 50% fake seems reasonable right?\n",
    "\n",
    "dfreal_trimmed = dfreal[-21_400 :]\n",
    "print('Real trimmed shape: ', dfreal_trimmed.shape)\n",
    "\n",
    "dffake_trimmed = dffake[-21_400 :]\n",
    "print('Fake trimmed shape: ', dffake_trimmed.shape)\n",
    "\n",
    "# and now combine them into one dataframe:\n",
    "df_joined = dfreal_trimmed.append(dffake_trimmed, ignore_index=True)\n",
    "\n",
    "#df_joined['date'] = pd.to_datetime(df_joined['date']).dt.date\n",
    "\n",
    "print()\n",
    "print('Combined and trimmed (equal parts Real and Fake) shape: ', df_joined.shape)\n",
    "print()\n",
    "#print(df_joined.head(1))\n",
    "df_joined.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20 00:00:00                                                                                                                                      182\n",
       "2017-12-06 00:00:00                                                                                                                                      166\n",
       "2017-11-30 00:00:00                                                                                                                                      162\n",
       "2017-11-09 00:00:00                                                                                                                                      158\n",
       "2017-10-13 00:00:00                                                                                                                                      155\n",
       "                                                                                                                                                        ... \n",
       "2016-01-24 00:00:00                                                                                                                                        1\n",
       "https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/      1\n",
       "2016-12-25 00:00:00                                                                                                                                        1\n",
       "2016-05-30 00:00:00                                                                                                                                        1\n",
       "Jul 19, 2015                                                                                                                                               1\n",
       "Name: date, Length: 2298, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "# remember to write about this in your data cleaning. leave this cell.... for proof. \n",
    "df_joined['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['title' 'text' 'subject' 'date' 'Fake'] not found in axis\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-0cb2cf876e90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#df_joined['date'].str.find(sub)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf_joined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_joined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_joined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_joined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdf_joined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_joined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_joined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_joined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Jul 19, 2015'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4303\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4304\u001b[0m         \"\"\"\n\u001b[1;32m-> 4305\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4306\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4150\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4152\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4185\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4186\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4187\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4188\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['title' 'text' 'subject' 'date' 'Fake'] not found in axis\""
     ]
    }
   ],
   "source": [
    "\n",
    "# we have to find the 2 values with wrong dates - one is a URL and one is just not a datetime. \n",
    "# they are the reason that our target vector and X are different lengths. \n",
    "\n",
    "#sub = 'https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/'\n",
    "#df_joined['date'].str.find(sub) \n",
    "\n",
    "df_joined = df_joined.drop(df_joined.loc[df_joined['date'] == 'https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/'])\n",
    "\n",
    "df_joined = df_joined.drop(df_joined.loc[df_joined['date'] == 'Jul 19, 2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:  (42798, 5)\ny shape:  (42800,)\n"
     ]
    }
   ],
   "source": [
    "# X and y split\n",
    "\n",
    "target = df_joined['Fake']\n",
    "\n",
    "X = df_joined.drop(df_joined['Fake'])\n",
    "\n",
    "y = target\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [42798, 42800]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-273a132217bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [42798, 42800]"
     ]
    }
   ],
   "source": [
    "# need to go lookup the params for train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline : 0.5\n"
     ]
    }
   ],
   "source": [
    "# this is silly but it's good form, so here's a baseline. \n",
    "print('Baseline :', df_joined['Fake'].value_counts().max()/len(df_joined['Fake']))"
   ]
  },
  {
   "source": [
    "# I don't think we'll use this but here's a Count Vectorizer just in case:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          according      american        called      campaign       clinton  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.314860      0.360047      0.295864      0.483551      0.617967   \n",
       "std        0.787661      1.064934      0.659172      1.348366      2.304393   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       20.000000     48.000000     10.000000     31.000000     67.000000   \n",
       "\n",
       "            country         court    democratic           did        donald  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.389182      0.329229      0.303621      0.369579      0.589720   \n",
       "std        0.904831      1.352565      0.888218      0.797904      1.019764   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max       26.000000     43.000000     18.000000     20.000000     32.000000   \n",
       "\n",
       "       ...       support          time          told         trump  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.297453      0.460584      0.529463      2.516986   \n",
       "std    ...      0.767365      0.909996      0.939871      4.381324   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      1.000000      1.000000      3.000000   \n",
       "max    ...     24.000000     28.000000     13.000000     73.000000   \n",
       "\n",
       "             united    washington          week         white          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.536192      0.421916      0.299743      0.482874      0.557079   \n",
       "std        1.283519      0.954844      0.675265      1.305999      1.120036   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max       42.000000     35.000000     10.000000     36.000000     27.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.386706  \n",
       "std        0.890860  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max       61.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>according</th>\n      <th>american</th>\n      <th>called</th>\n      <th>campaign</th>\n      <th>clinton</th>\n      <th>country</th>\n      <th>court</th>\n      <th>democratic</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>...</th>\n      <th>support</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>week</th>\n      <th>white</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.314860</td>\n      <td>0.360047</td>\n      <td>0.295864</td>\n      <td>0.483551</td>\n      <td>0.617967</td>\n      <td>0.389182</td>\n      <td>0.329229</td>\n      <td>0.303621</td>\n      <td>0.369579</td>\n      <td>0.589720</td>\n      <td>...</td>\n      <td>0.297453</td>\n      <td>0.460584</td>\n      <td>0.529463</td>\n      <td>2.516986</td>\n      <td>0.536192</td>\n      <td>0.421916</td>\n      <td>0.299743</td>\n      <td>0.482874</td>\n      <td>0.557079</td>\n      <td>0.386706</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.787661</td>\n      <td>1.064934</td>\n      <td>0.659172</td>\n      <td>1.348366</td>\n      <td>2.304393</td>\n      <td>0.904831</td>\n      <td>1.352565</td>\n      <td>0.888218</td>\n      <td>0.797904</td>\n      <td>1.019764</td>\n      <td>...</td>\n      <td>0.767365</td>\n      <td>0.909996</td>\n      <td>0.939871</td>\n      <td>4.381324</td>\n      <td>1.283519</td>\n      <td>0.954844</td>\n      <td>0.675265</td>\n      <td>1.305999</td>\n      <td>1.120036</td>\n      <td>0.890860</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20.000000</td>\n      <td>48.000000</td>\n      <td>10.000000</td>\n      <td>31.000000</td>\n      <td>67.000000</td>\n      <td>26.000000</td>\n      <td>43.000000</td>\n      <td>18.000000</td>\n      <td>20.000000</td>\n      <td>32.000000</td>\n      <td>...</td>\n      <td>24.000000</td>\n      <td>28.000000</td>\n      <td>13.000000</td>\n      <td>73.000000</td>\n      <td>42.000000</td>\n      <td>35.000000</td>\n      <td>10.000000</td>\n      <td>36.000000</td>\n      <td>27.000000</td>\n      <td>61.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# instantiate the count vectorizer:\n",
    "cv = CountVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, max_df = 0.95 , min_df = 0.01 )\n",
    "\n",
    "# here's a function to return a dataframe:\n",
    "\n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "# now here's the actual \"thing\":\n",
    "\n",
    "df_joined_CountVector = create_term_matrix(df_joined['text'], cv)\n",
    "\n",
    "df_joined_CountVector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after reading today, it would appear that the results of the Tf-IDF Vectorizer are the same results are doing a Count Vectorizer followed by a Tf-IDF Transform. \n",
    "# Everyone I spoke to from lambda seemed to think the only model I should run here is probably the GradientBoostingClassifier. \n",
    "# I've been reading documentation on how to adjust TF-IDF Vectorizer.\n",
    "# I still have questions regarding how to merge the results from this with my orginal df_joined(41,800 x 5) - so pin in that for now. \n",
    "\n",
    "# finally got git bash working with my github repo - big shoutout to Jacob Maxfield and Josh Carlisle. \n",
    "# getting a bit confused by pipenv install not working with the nltk package - don't need it for this though, maybe anaconda later... \n",
    "# create a dictionary for myself (ex: year and years same word) - (sisichen)\n",
    "# find an NLP function that can cluster similiar words together - lookup common NLP functions - (sisichen)\n",
    "# merging original frame and target vector with results so that I can train test split and fit model...\n",
    "# Ngrams. need to grok that. sequences of words, but how many and in what order??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                did        donald    government        house          just  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.00000  42800.000000   \n",
       "mean       0.057976      0.074466      0.095030      0.08585      0.081363   \n",
       "std        0.124791      0.119814      0.190170      0.17762      0.157345   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%        0.052583      0.122620      0.113733      0.09145      0.114226   \n",
       "max        1.000000      1.000000      1.000000      1.00000      1.000000   \n",
       "\n",
       "               like           new          news        people     president  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.077764      0.093913      0.076367      0.120285      0.138979   \n",
       "std        0.158730      0.168262      0.168511      0.192650      0.183979   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.065588   \n",
       "75%        0.098738      0.140378      0.056638      0.186211      0.230136   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...          said         state        states          time  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.284218      0.105809      0.081443      0.070904   \n",
       "std    ...      0.254732      0.197131      0.150900      0.139149   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.245756      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.470876      0.144329      0.122476      0.103186   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               told         trump        united    washington          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.080791      0.240466      0.075833      0.068417      0.084779   \n",
       "std        0.142332      0.313201      0.152335      0.136781      0.161208   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.130166      0.491378      0.087378      0.088731      0.121411   \n",
       "max        1.000000      1.000000      0.980872      1.000000      1.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.061547  \n",
       "std        0.133028  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.039868  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.00000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.057976</td>\n      <td>0.074466</td>\n      <td>0.095030</td>\n      <td>0.08585</td>\n      <td>0.081363</td>\n      <td>0.077764</td>\n      <td>0.093913</td>\n      <td>0.076367</td>\n      <td>0.120285</td>\n      <td>0.138979</td>\n      <td>...</td>\n      <td>0.284218</td>\n      <td>0.105809</td>\n      <td>0.081443</td>\n      <td>0.070904</td>\n      <td>0.080791</td>\n      <td>0.240466</td>\n      <td>0.075833</td>\n      <td>0.068417</td>\n      <td>0.084779</td>\n      <td>0.061547</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.124791</td>\n      <td>0.119814</td>\n      <td>0.190170</td>\n      <td>0.17762</td>\n      <td>0.157345</td>\n      <td>0.158730</td>\n      <td>0.168262</td>\n      <td>0.168511</td>\n      <td>0.192650</td>\n      <td>0.183979</td>\n      <td>...</td>\n      <td>0.254732</td>\n      <td>0.197131</td>\n      <td>0.150900</td>\n      <td>0.139149</td>\n      <td>0.142332</td>\n      <td>0.313201</td>\n      <td>0.152335</td>\n      <td>0.136781</td>\n      <td>0.161208</td>\n      <td>0.133028</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.065588</td>\n      <td>...</td>\n      <td>0.245756</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.052583</td>\n      <td>0.122620</td>\n      <td>0.113733</td>\n      <td>0.09145</td>\n      <td>0.114226</td>\n      <td>0.098738</td>\n      <td>0.140378</td>\n      <td>0.056638</td>\n      <td>0.186211</td>\n      <td>0.230136</td>\n      <td>...</td>\n      <td>0.470876</td>\n      <td>0.144329</td>\n      <td>0.122476</td>\n      <td>0.103186</td>\n      <td>0.130166</td>\n      <td>0.491378</td>\n      <td>0.087378</td>\n      <td>0.088731</td>\n      <td>0.121411</td>\n      <td>0.039868</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.980872</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# alright, let's see if I can generate anything to show for myself re: TF-IDF Vectorizer... \n",
    "\n",
    "# instantiate:\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 100, min_df= 0.25 , max_df= 0.75)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector = create_term_matrix(df_joined['text'], tfidf)\n",
    "\n",
    "df_joined_tfidfvector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        did    donald  government  house      just      like       new  news  \\\n",
       "0  0.000000  0.190417    0.000000    0.0  0.000000  0.000000  0.201728   0.0   \n",
       "1  0.151817  0.123320    0.143931    0.0  0.000000  0.142834  0.130646   0.0   \n",
       "2  0.000000  0.222648    0.000000    0.0  0.000000  0.000000  0.235874   0.0   \n",
       "3  0.000000  0.119469    0.139435    0.0  0.000000  0.000000  0.126565   0.0   \n",
       "4  0.000000  0.064417    0.075183    0.0  0.071857  0.000000  0.818922   0.0   \n",
       "\n",
       "     people  president  ...      said     state    states      time      told  \\\n",
       "0  0.000000   0.163035  ...  0.000000  0.000000  0.000000  0.432390  0.000000   \n",
       "1  0.119388   0.211174  ...  0.250203  0.271883  0.697557  0.000000  0.000000   \n",
       "2  0.000000   0.190631  ...  0.150576  0.000000  0.000000  0.000000  0.719675   \n",
       "3  0.115659   0.204578  ...  0.323185  0.131696  0.405462  0.000000  0.000000   \n",
       "4  0.000000   0.055154  ...  0.479215  0.000000  0.072874  0.219412  0.000000   \n",
       "\n",
       "      trump    united  washington      year    years  \n",
       "0  0.524292  0.000000    0.000000  0.638001  0.00000  \n",
       "1  0.113183  0.147631    0.291535  0.000000  0.00000  \n",
       "2  0.408690  0.000000    0.000000  0.000000  0.00000  \n",
       "3  0.548239  0.429059    0.141215  0.133428  0.14765  \n",
       "4  0.118243  0.077116    0.000000  0.071944  0.00000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.190417</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.201728</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.163035</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.432390</td>\n      <td>0.000000</td>\n      <td>0.524292</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.638001</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.151817</td>\n      <td>0.123320</td>\n      <td>0.143931</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.142834</td>\n      <td>0.130646</td>\n      <td>0.0</td>\n      <td>0.119388</td>\n      <td>0.211174</td>\n      <td>...</td>\n      <td>0.250203</td>\n      <td>0.271883</td>\n      <td>0.697557</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.113183</td>\n      <td>0.147631</td>\n      <td>0.291535</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.222648</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.235874</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.190631</td>\n      <td>...</td>\n      <td>0.150576</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.719675</td>\n      <td>0.408690</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.119469</td>\n      <td>0.139435</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.126565</td>\n      <td>0.0</td>\n      <td>0.115659</td>\n      <td>0.204578</td>\n      <td>...</td>\n      <td>0.323185</td>\n      <td>0.131696</td>\n      <td>0.405462</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.548239</td>\n      <td>0.429059</td>\n      <td>0.141215</td>\n      <td>0.133428</td>\n      <td>0.14765</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.064417</td>\n      <td>0.075183</td>\n      <td>0.0</td>\n      <td>0.071857</td>\n      <td>0.000000</td>\n      <td>0.818922</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.055154</td>\n      <td>...</td>\n      <td>0.479215</td>\n      <td>0.000000</td>\n      <td>0.072874</td>\n      <td>0.219412</td>\n      <td>0.000000</td>\n      <td>0.118243</td>\n      <td>0.077116</td>\n      <td>0.000000</td>\n      <td>0.071944</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df_joined_tfidfvector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 42800 entries, 0 to 42799\nData columns (total 22 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   did         42800 non-null  float64\n 1   donald      42800 non-null  float64\n 2   government  42800 non-null  float64\n 3   house       42800 non-null  float64\n 4   just        42800 non-null  float64\n 5   like        42800 non-null  float64\n 6   new         42800 non-null  float64\n 7   news        42800 non-null  float64\n 8   people      42800 non-null  float64\n 9   president   42800 non-null  float64\n 10  republican  42800 non-null  float64\n 11  reuters     42800 non-null  float64\n 12  said        42800 non-null  float64\n 13  state       42800 non-null  float64\n 14  states      42800 non-null  float64\n 15  time        42800 non-null  float64\n 16  told        42800 non-null  float64\n 17  trump       42800 non-null  float64\n 18  united      42800 non-null  float64\n 19  washington  42800 non-null  float64\n 20  year        42800 non-null  float64\n 21  years       42800 non-null  float64\ndtypes: float64(22)\nmemory usage: 7.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_joined_tfidfvector.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline\n",
    "# model = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(lowercase=True, ngram_range=(1,1))),\n",
    "#     ('dim_red', TruncatedSVD(n_components=50, random_state=42)),\n",
    "#     ('predictor', GradientBoostingClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Fit model to training data\n",
    "# model.fit(X_train, y_train); \n",
    "\n",
    "# REMEMBER TO GET A VALIDATION SPLIT AND CHECK IT AGAINST THAT. "
   ]
  }
 ]
}