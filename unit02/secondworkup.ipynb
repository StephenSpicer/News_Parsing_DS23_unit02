{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our preamble cell :\n",
    "# remember to check for anything missing \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real data shape:  (21417, 5)\n",
      "Fake data shape:  (23481, 5)\n"
     ]
    }
   ],
   "source": [
    "# OK, importing and minor cleaning first. \n",
    "\n",
    "dfreal = pd.read_csv('True.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "dfreal['Fake'] = 0\n",
    "print('Real data shape: ', dfreal.shape)\n",
    "\n",
    "dffake = pd.read_csv('Fake.csv',\n",
    "                    parse_dates = ['date'])\n",
    "#                    index_col = 'date')\n",
    "\n",
    "dffake['Fake'] = 1\n",
    "print('Fake data shape: ', dffake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20    182\n",
       "2017-12-06    166\n",
       "2017-11-30    162\n",
       "2017-11-09    158\n",
       "2017-10-13    155\n",
       "             ... \n",
       "2016-09-11      1\n",
       "2016-05-14      1\n",
       "2016-05-30      1\n",
       "2016-08-06      1\n",
       "2016-09-03      1\n",
       "Name: date, Length: 716, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# this is proof that only the fake csv has garbage dates in it, which is why none of the parse dates worked. \n",
    "dfreal['date'].value_counts()\n",
    "#.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "May 10, 2017                                                                                                                                             46\n",
       "May 5, 2016                                                                                                                                              44\n",
       "May 26, 2016                                                                                                                                             44\n",
       "May 6, 2016                                                                                                                                              44\n",
       "May 11, 2016                                                                                                                                             43\n",
       "                                                                                                                                                         ..\n",
       "November 20, 2017                                                                                                                                         1\n",
       "November 19, 2017                                                                                                                                         1\n",
       "https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/     1\n",
       "October 9, 2017                                                                                                                                           1\n",
       "Jul 19, 2015                                                                                                                                              1\n",
       "Name: date, Length: 1681, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "dffake['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(23481, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "\n",
    "# dffake = \n",
    "comma_list = pd.DataFrame(dffake['date'].str.find(','))\n",
    "\n",
    "comma_list.value_counts()\n",
    "comma_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~df['your column'].isin(['list of strings'])]\n",
    "# http = ['http',\".com\"]\n",
    "# dffake2 = dffake[~dffake.date.isin(http)]\n",
    "\n",
    "searchfor = ['http', '-', 'MSNBC']\n",
    "dffake2 = dffake[~dffake['date'].str.contains('|'.join(searchfor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "May 10, 2017         46\n",
       "May 26, 2016         44\n",
       "May 6, 2016          44\n",
       "May 5, 2016          44\n",
       "May 11, 2016         43\n",
       "                     ..\n",
       "October 9, 2017       1\n",
       "December 19, 2017     1\n",
       "November 19, 2017     1\n",
       "October 22, 2017      1\n",
       "December 9, 2017      1\n",
       "Name: date, Length: 1669, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "dffake2['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(23436, 5)\n(21417, 5)\n"
     ]
    }
   ],
   "source": [
    "print(dffake2.shape)\n",
    "print(dfreal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dffake2['date'] = pd.to_datetime(dffake2['date'], format='%m%d%y')\n",
    "# dffake2['date'] = dffake2['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real trimmed shape:  (21400, 5)\nFake trimmed shape:  (21400, 5)\n\nCombined and trimmed (equal parts Real and Fake) shape:  (42800, 5)\n\n"
     ]
    }
   ],
   "source": [
    "# now I'll trim those up so they are the same length - \n",
    "# 50% real 50% fake seems reasonable right?\n",
    "\n",
    "dfreal_trimmed = dfreal[-21_400 :]\n",
    "print('Real trimmed shape: ', dfreal_trimmed.shape)\n",
    "\n",
    "dffake_trimmed = dffake2[-21_400 :]\n",
    "print('Fake trimmed shape: ', dffake_trimmed.shape)\n",
    "\n",
    "# and now combine them into one dataframe:\n",
    "df_joined = dfreal_trimmed.append(dffake_trimmed, ignore_index=True)\n",
    "\n",
    "df_joined['date'] = pd.to_datetime(df_joined['date'])\n",
    "\n",
    "print()\n",
    "print('Combined and trimmed (equal parts Real and Fake) shape: ', df_joined.shape)\n",
    "print()\n",
    "#print(df_joined.head(1))\n",
    "#df_joined.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2017-12-20    194\n",
       "2017-12-06    180\n",
       "2017-11-09    178\n",
       "2017-11-30    175\n",
       "2017-10-13    171\n",
       "             ... \n",
       "2015-06-21      1\n",
       "2015-06-07      1\n",
       "2015-07-19      1\n",
       "2015-07-18      1\n",
       "2015-04-02      1\n",
       "Name: date, Length: 1004, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "df_joined['date'].value_counts()\n",
    "\n",
    "# Holy Smokes I think all the date times are clean. \n",
    "# Let's never spend 2 days on that again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All URL's and Wrong-Dates seem to be corrected. Finally.  \n",
    "# X and y are still not the same length - need to fix that... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:  (42800, 4)\ny shape:  (42800,)\n"
     ]
    }
   ],
   "source": [
    "# X and y split\n",
    "\n",
    "target = df_joined['Fake']\n",
    "\n",
    "X = df_joined.drop(['Fake'], axis=1)\n",
    "\n",
    "y = target\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline : 0.5\n"
     ]
    }
   ],
   "source": [
    "# this is silly but it's good form, so here's a baseline. \n",
    "print('Baseline :', df_joined['Fake'].value_counts().max()/len(df_joined['Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split:\n",
    "\n",
    "# leaving this code here in case I set up my target wrong. \n",
    "# X = df.drop(['target'],axis=1).values   # independant features\n",
    "# y = df['target'].values\t\t\t\t\t# dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# doing 25/75 split and 42. \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24075, 4)\n(24075,)\n(8025, 4)\n(8025,)\n(10700, 4)\n(10700,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wonderful. All variables should be set up the right way... but I will still check in with someone about whether I did this right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump on Twitter (Dec 26) - Hillary Clinton, T...   \n",
       "1  U.S. appeals court rejects challenge to Trump ...   \n",
       "2  Treasury Secretary Mnuchin was sent gift-wrapp...   \n",
       "3  Federal judge partially lifts Trump's latest r...   \n",
       "4  Exclusive: U.S. memo weakens guidelines for pr...   \n",
       "\n",
       "                                                text       subject       date  \\\n",
       "0  The following statements were posted to the ve...  politicsNews 2017-12-26   \n",
       "1  (Reuters) - A U.S. appeals court in Washington...  politicsNews 2017-12-26   \n",
       "2  (Reuters) - A gift-wrapped package addressed t...  politicsNews 2017-12-24   \n",
       "3  WASHINGTON (Reuters) - A federal judge in Seat...  politicsNews 2017-12-24   \n",
       "4  NEW YORK (Reuters) - The U.S. Justice Departme...  politicsNews 2017-12-23   \n",
       "\n",
       "   Fake  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>Fake</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Trump on Twitter (Dec 26) - Hillary Clinton, T...</td>\n      <td>The following statements were posted to the ve...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. appeals court rejects challenge to Trump ...</td>\n      <td>(Reuters) - A U.S. appeals court in Washington...</td>\n      <td>politicsNews</td>\n      <td>2017-12-26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Treasury Secretary Mnuchin was sent gift-wrapp...</td>\n      <td>(Reuters) - A gift-wrapped package addressed t...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Federal judge partially lifts Trump's latest r...</td>\n      <td>WASHINGTON (Reuters) - A federal judge in Seat...</td>\n      <td>politicsNews</td>\n      <td>2017-12-24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Exclusive: U.S. memo weakens guidelines for pr...</td>\n      <td>NEW YORK (Reuters) - The U.S. Justice Departme...</td>\n      <td>politicsNews</td>\n      <td>2017-12-23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "df_joined.head()"
   ]
  },
  {
   "source": [
    "## *I don't think we'll use this but here's a Count Vectorizer just in case:*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          according      american        called      campaign       clinton  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.315047      0.360117      0.295794      0.483505      0.618014   \n",
       "std        0.787854      1.065031      0.658973      1.347394      2.304309   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       20.000000     48.000000     10.000000     31.000000     67.000000   \n",
       "\n",
       "            country         court    democratic           did        donald  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.389159      0.329299      0.303575      0.369673      0.590771   \n",
       "std        0.904674      1.353023      0.888128      0.797977      1.020930   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max       26.000000     43.000000     18.000000     20.000000     32.000000   \n",
       "\n",
       "       ...       support          time          told         trump  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.297734      0.460935      0.529416      2.523014   \n",
       "std    ...      0.768017      0.910293      0.939773      4.386813   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      1.000000      1.000000      3.000000   \n",
       "max    ...     24.000000     28.000000     13.000000     73.000000   \n",
       "\n",
       "             united    washington          week         white          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.536028      0.422009      0.299813      0.483178      0.557126   \n",
       "std        1.283105      0.954925      0.675320      1.305252      1.120097   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max       42.000000     35.000000     10.000000     36.000000     27.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.386589  \n",
       "std        0.890714  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max       61.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>according</th>\n      <th>american</th>\n      <th>called</th>\n      <th>campaign</th>\n      <th>clinton</th>\n      <th>country</th>\n      <th>court</th>\n      <th>democratic</th>\n      <th>did</th>\n      <th>donald</th>\n      <th>...</th>\n      <th>support</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>week</th>\n      <th>white</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.315047</td>\n      <td>0.360117</td>\n      <td>0.295794</td>\n      <td>0.483505</td>\n      <td>0.618014</td>\n      <td>0.389159</td>\n      <td>0.329299</td>\n      <td>0.303575</td>\n      <td>0.369673</td>\n      <td>0.590771</td>\n      <td>...</td>\n      <td>0.297734</td>\n      <td>0.460935</td>\n      <td>0.529416</td>\n      <td>2.523014</td>\n      <td>0.536028</td>\n      <td>0.422009</td>\n      <td>0.299813</td>\n      <td>0.483178</td>\n      <td>0.557126</td>\n      <td>0.386589</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.787854</td>\n      <td>1.065031</td>\n      <td>0.658973</td>\n      <td>1.347394</td>\n      <td>2.304309</td>\n      <td>0.904674</td>\n      <td>1.353023</td>\n      <td>0.888128</td>\n      <td>0.797977</td>\n      <td>1.020930</td>\n      <td>...</td>\n      <td>0.768017</td>\n      <td>0.910293</td>\n      <td>0.939773</td>\n      <td>4.386813</td>\n      <td>1.283105</td>\n      <td>0.954925</td>\n      <td>0.675320</td>\n      <td>1.305252</td>\n      <td>1.120097</td>\n      <td>0.890714</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20.000000</td>\n      <td>48.000000</td>\n      <td>10.000000</td>\n      <td>31.000000</td>\n      <td>67.000000</td>\n      <td>26.000000</td>\n      <td>43.000000</td>\n      <td>18.000000</td>\n      <td>20.000000</td>\n      <td>32.000000</td>\n      <td>...</td>\n      <td>24.000000</td>\n      <td>28.000000</td>\n      <td>13.000000</td>\n      <td>73.000000</td>\n      <td>42.000000</td>\n      <td>35.000000</td>\n      <td>10.000000</td>\n      <td>36.000000</td>\n      <td>27.000000</td>\n      <td>61.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "# instantiate the count vectorizer:\n",
    "cv = CountVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, max_df = 0.95 , min_df = 0.01 )\n",
    "\n",
    "# here's a function to return a dataframe:\n",
    "\n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "# now here's the actual \"thing\":\n",
    "\n",
    "df_joined_CountVector = create_term_matrix(df_joined['text'], cv)\n",
    "\n",
    "df_joined_CountVector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-IDF Vectorizer are the same results are doing a Count Vectorizer followed by a Tf-IDF Transform. \n",
    "# GradientBoostingClassifier. Good thing we learned some params today. \n",
    "# \n",
    "# I still have questions regarding how to merge the results from this with my orginal df_joined(41,800 x 5) - so pin in that for now. \n",
    "\n",
    "# \n",
    "# create a dictionary for myself (ex: year and years same word) - (sisichen)\n",
    "# find an NLP function that can cluster similiar words together - lookup common NLP functions - (sisichen)\n",
    "\n",
    "# merging original frame and target vector with results so that I can train test split and fit model...\n",
    "# Ngrams. They exist in the parameters for the vectorizer / model below... "
   ]
  },
  {
   "source": [
    "## *now for TF-IDF*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                did        donald    government         house          just  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.057967      0.074543      0.095066      0.085921      0.081424   \n",
       "std        0.124761      0.119868      0.190222      0.177617      0.157294   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.052837      0.122746      0.113759      0.091760      0.114470   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               like           new          news        people     president  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.077734      0.093882      0.076336      0.120271      0.139008   \n",
       "std        0.158628      0.168228      0.168455      0.192616      0.183971   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.065831   \n",
       "75%        0.098803      0.140322      0.056671      0.186142      0.230169   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...          said         state        states          time  \\\n",
       "count  ...  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean   ...      0.284245      0.105763      0.081423      0.070897   \n",
       "std    ...      0.254718      0.197059      0.150857      0.139093   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.245803      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.470852      0.144302      0.122473      0.103245   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               told         trump        united    washington          year  \\\n",
       "count  42800.000000  42800.000000  42800.000000  42800.000000  42800.000000   \n",
       "mean       0.080758      0.240842      0.075819      0.068428      0.084785   \n",
       "std        0.142268      0.313414      0.152301      0.136795      0.161222   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.130172      0.492389      0.087407      0.088721      0.121459   \n",
       "max        1.000000      1.000000      0.980876      1.000000      1.000000   \n",
       "\n",
       "              years  \n",
       "count  42800.000000  \n",
       "mean       0.061514  \n",
       "std        0.132984  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.039246  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>donald</th>\n      <th>government</th>\n      <th>house</th>\n      <th>just</th>\n      <th>like</th>\n      <th>new</th>\n      <th>news</th>\n      <th>people</th>\n      <th>president</th>\n      <th>...</th>\n      <th>said</th>\n      <th>state</th>\n      <th>states</th>\n      <th>time</th>\n      <th>told</th>\n      <th>trump</th>\n      <th>united</th>\n      <th>washington</th>\n      <th>year</th>\n      <th>years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>...</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.057967</td>\n      <td>0.074543</td>\n      <td>0.095066</td>\n      <td>0.085921</td>\n      <td>0.081424</td>\n      <td>0.077734</td>\n      <td>0.093882</td>\n      <td>0.076336</td>\n      <td>0.120271</td>\n      <td>0.139008</td>\n      <td>...</td>\n      <td>0.284245</td>\n      <td>0.105763</td>\n      <td>0.081423</td>\n      <td>0.070897</td>\n      <td>0.080758</td>\n      <td>0.240842</td>\n      <td>0.075819</td>\n      <td>0.068428</td>\n      <td>0.084785</td>\n      <td>0.061514</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.124761</td>\n      <td>0.119868</td>\n      <td>0.190222</td>\n      <td>0.177617</td>\n      <td>0.157294</td>\n      <td>0.158628</td>\n      <td>0.168228</td>\n      <td>0.168455</td>\n      <td>0.192616</td>\n      <td>0.183971</td>\n      <td>...</td>\n      <td>0.254718</td>\n      <td>0.197059</td>\n      <td>0.150857</td>\n      <td>0.139093</td>\n      <td>0.142268</td>\n      <td>0.313414</td>\n      <td>0.152301</td>\n      <td>0.136795</td>\n      <td>0.161222</td>\n      <td>0.132984</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.065831</td>\n      <td>...</td>\n      <td>0.245803</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.052837</td>\n      <td>0.122746</td>\n      <td>0.113759</td>\n      <td>0.091760</td>\n      <td>0.114470</td>\n      <td>0.098803</td>\n      <td>0.140322</td>\n      <td>0.056671</td>\n      <td>0.186142</td>\n      <td>0.230169</td>\n      <td>...</td>\n      <td>0.470852</td>\n      <td>0.144302</td>\n      <td>0.122473</td>\n      <td>0.103245</td>\n      <td>0.130172</td>\n      <td>0.492389</td>\n      <td>0.087407</td>\n      <td>0.088721</td>\n      <td>0.121459</td>\n      <td>0.039246</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.980876</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "# alright, let's see if I can generate anything to show for myself re: TF-IDF Vectorizer... \n",
    "\n",
    "# instantiate:\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 100, min_df= 0.25 , max_df= 0.75)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector = create_term_matrix(df_joined['text'], tfidf)\n",
    "\n",
    "df_joined_tfidfvector.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          president       reuters          said\n",
       "count  42800.000000  42800.000000  42800.000000\n",
       "mean       0.317227      0.206191      0.585572\n",
       "std        0.368417      0.262745      0.397562\n",
       "min        0.000000      0.000000      0.000000\n",
       "25%        0.000000      0.000000      0.000000\n",
       "50%        0.148918      0.084481      0.741972\n",
       "75%        0.612889      0.368261      0.951749\n",
       "max        1.000000      1.000000      1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>president</th>\n      <th>reuters</th>\n      <th>said</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n      <td>42800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.317227</td>\n      <td>0.206191</td>\n      <td>0.585572</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.368417</td>\n      <td>0.262745</td>\n      <td>0.397562</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.148918</td>\n      <td>0.084481</td>\n      <td>0.741972</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.612889</td>\n      <td>0.368261</td>\n      <td>0.951749</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "# instantiate 2nd: much different mix max:\n",
    "tfidf2 = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 100, min_df= 0.5 , max_df= 0.99)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector2 = create_term_matrix(df_joined['text'], tfidf2)\n",
    "\n",
    "df_joined_tfidfvector2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        according  american    called  campaign   country       did    donald  \\\n",
       "0       0.000000  0.000000  0.000000  0.498824  0.000000  0.000000  0.192121   \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.143514  0.116522   \n",
       "2       0.331001  0.000000  0.000000  0.000000  0.000000  0.000000  0.249475   \n",
       "3       0.184967  0.000000  0.364490  0.000000  0.348085  0.000000  0.139410   \n",
       "4       0.000000  0.000000  0.090353  0.000000  0.086286  0.000000  0.069116   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "42795   0.305618  0.153602  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "42796   0.000000  0.000000  0.000000  0.000000  0.000000  0.745385  0.000000   \n",
       "42797   0.062684  0.000000  0.061761  0.000000  0.058982  0.058189  0.000000   \n",
       "42798   0.000000  0.000000  0.000000  0.000000  0.000000  0.483405  0.000000   \n",
       "42799   0.534158  0.322159  0.105259  0.104530  0.100522  0.000000  0.000000   \n",
       "\n",
       "       election     going  government  ...    states      time      told  \\\n",
       "0      0.000000  0.259713    0.000000  ...  0.000000  0.436389  0.000000   \n",
       "1      0.301517  0.000000    0.136075  ...  0.659463  0.000000  0.000000   \n",
       "2      0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.806885   \n",
       "3      0.000000  0.000000    0.162803  ...  0.473397  0.000000  0.000000   \n",
       "4      0.000000  0.093432    0.080714  ...  0.078233  0.235488  0.000000   \n",
       "...         ...       ...         ...  ...       ...       ...       ...   \n",
       "42795  0.000000  0.000000    0.000000  ...  0.260729  0.130803  0.000000   \n",
       "42796  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.000000   \n",
       "42797  0.000000  0.000000    0.331036  ...  0.160430  0.160970  0.076403   \n",
       "42798  0.000000  0.000000    0.000000  ...  0.000000  0.222877  0.000000   \n",
       "42799  0.208353  0.000000    0.000000  ...  0.000000  0.274339  0.086808   \n",
       "\n",
       "         united  washington       way      week     white      year     years  \n",
       "0      0.000000    0.000000  0.000000  0.000000  0.000000  0.644126  0.000000  \n",
       "1      0.139562    0.275613  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.000000    0.000000  0.000000  0.327407  0.000000  0.000000  0.000000  \n",
       "3      0.500926    0.164874  0.187637  0.000000  0.000000  0.155800  0.172414  \n",
       "4      0.082782    0.000000  0.000000  0.000000  0.000000  0.077242  0.000000  \n",
       "...         ...         ...       ...       ...       ...       ...       ...  \n",
       "42795  0.275891    0.136210  0.155015  0.151150  0.000000  0.000000  0.000000  \n",
       "42796  0.000000    0.000000  0.000000  0.397125  0.000000  0.000000  0.000000  \n",
       "42797  0.056587    0.530808  0.158972  0.155008  0.000000  0.026400  0.175289  \n",
       "42798  0.000000    0.000000  0.264133  0.000000  0.000000  0.219317  0.000000  \n",
       "42799  0.000000    0.095227  0.000000  0.000000  0.103342  0.089986  0.000000  \n",
       "\n",
       "[42800 rows x 35 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "# instantiate: once again, different min max. \n",
    "\n",
    "tfidf3 = TfidfVectorizer(stop_words = 'english', strip_accents ='ascii', max_features = 50, min_df= 0.2 , max_df= 0.4)\n",
    "# ngram_range=(1,2) - we're gonna play with the ngrams soon, be patient. \n",
    "def create_term_matrix(message_list, vectorizer):\n",
    "    doc_term_df = vectorizer.fit_transform(message_list)\n",
    "    return DataFrame(doc_term_df.toarray(),\n",
    "                     columns=vectorizer.get_feature_names())\n",
    "\n",
    "df_joined_tfidfvector3 = create_term_matrix(df_joined['text'], tfidf3)\n",
    "\n",
    "df_joined_tfidfvector3.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "# that should be pip installed now. \n",
    "# also pip installed plotly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24075, 4)\n(24075,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline\n",
    "model1 = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(lowercase=True, stop_words = 'english', strip_accents ='ascii', max_features = 100, ngram_range=(1,1))),\n",
    "    ('dim_red', TruncatedSVD(n_components=50, random_state=42)),\n",
    "    ('predictor', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model to training data\n",
    "model1.fit(X_train, y_train); \n",
    "\n"
   ]
  }
 ]
}